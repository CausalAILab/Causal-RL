{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc39db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from collections import deque\n",
    "\n",
    "from causal_gym import HighwayPCH\n",
    "from imitation.imitate import parse_graph, find_sequential_pi_backdoor, collect_expert_trajectories\n",
    "from imitation.gym_gail.core_net import DiscreteActor, Critic, Discriminator\n",
    "from imitation.gym_gail.causal_gail import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0a8d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 30\n",
    "seed = 1\n",
    "expert_eps = 200\n",
    "train_eps = 30\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2344c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = HighwayPCH(num_steps=num_steps, seed=seed, render_mode='rgb_array')\n",
    "num_actions = env.env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ecf3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = parse_graph(env.get_graph)\n",
    "X = {f'X{t}' for t in range(num_steps)}\n",
    "Y = f'Y{num_steps}'\n",
    "obs_prefix = env.env.observed_unobserved_vars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6de747b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_dim = 145  | encode(dummy_obs, 0).size = 145\n"
     ]
    }
   ],
   "source": [
    "Z_sets = find_sequential_pi_backdoor(G, X, Y, obs_prefix)\n",
    "categorical_dims = calc_categorical_dims(env)\n",
    "dummy_obs, _ = env.reset(seed=seed)\n",
    "\n",
    "encode, z_dim, union_tokens, var_dims = build_z_encoder(Z_sets, dummy_obs, categorical_dims)\n",
    "dummy_z = encode(dummy_obs, 0)\n",
    "print('z_dim =', z_dim, ' | encode(dummy_obs, 0).size =', int(np.asarray(dummy_z).size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68234c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting episode 1/10...\n",
      "  Episode 1 ended at step 10 (terminated: False, truncated: True).\n",
      "Starting episode 2/10...\n",
      "  Episode 2 ended at step 10 (terminated: False, truncated: True).\n",
      "Starting episode 3/10...\n",
      "  Episode 3 ended at step 10 (terminated: False, truncated: True).\n",
      "Starting episode 4/10...\n",
      "  Episode 4 ended at step 10 (terminated: True, truncated: True).\n",
      "Starting episode 5/10...\n",
      "  Episode 5 ended at step 10 (terminated: False, truncated: True).\n",
      "Starting episode 6/10...\n",
      "  Episode 6 ended at step 10 (terminated: False, truncated: True).\n",
      "Starting episode 7/10...\n",
      "  Episode 7 ended at step 10 (terminated: False, truncated: True).\n",
      "Starting episode 8/10...\n",
      "  Episode 8 ended at step 10 (terminated: False, truncated: True).\n",
      "Starting episode 9/10...\n",
      "  Episode 9 ended at step 10 (terminated: False, truncated: True).\n",
      "Starting episode 10/10...\n",
      "  Episode 10 ended at step 7 (terminated: True, truncated: False).\n",
      "Finished collecting expert trajectories.\n"
     ]
    }
   ],
   "source": [
    "records = collect_expert_trajectories(\n",
    "    env,\n",
    "    num_episodes=expert_eps,\n",
    "    max_steps=num_steps,\n",
    "    behavioral_policy=None,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaae8c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = DiscreteActor(z_dim, num_actions, hidden_size=128).to(device)\n",
    "critic = Critic(z_dim, hidden_size=128).to(device)\n",
    "discriminator = Discriminator(z_dim + num_actions, hidden_size=128, dropout=0.2).to(device)\n",
    "\n",
    "actor_optim = Adam(actor.parameters(), lr=3e-4)\n",
    "critic_optim = Adam(critic.parameters(), lr=1e-3)\n",
    "discriminator_optim = Adam(discriminator.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa9c7a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([97, 145]) torch.Size([97]) torch.Size([97, 150])\n"
     ]
    }
   ],
   "source": [
    "Z_e, A_e, X_e = make_expert_batch(records, encode, num_actions)\n",
    "print(Z_e.shape, A_e.shape, X_e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9790e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 completed.\n",
      "Epoch 2/5 completed.\n",
      "Epoch 3/5 completed.\n",
      "Epoch 4/5 completed.\n",
      "Epoch 5/5 completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'avg_env_return': 166.325410816414,\n",
       " 'avg_D_reward': 0.6946890950202942,\n",
       " 'ppo_actor_loss': -0.026710760965943336,\n",
       " 'ppo_critic_loss': 1.1620875358581544,\n",
       " 'ppo_entropy': 1.6088080167770387,\n",
       " 'ppo_approx_kl': 0.004577630899079588,\n",
       " 'ppo_clip_frac': 0.0,\n",
       " 'D_loss': 10.692280451456705,\n",
       " 'D_real_mean': 0.007911172385017077,\n",
       " 'D_fake_mean': 0.0035715773701667786,\n",
       " 'D_gp': 0.9308118224143982,\n",
       " 'D_accuracy': 0.6078431407610575,\n",
       " 'ep_lens': [10, 10, 10, 7, 5, 10, 3, 10, 10, 10],\n",
       " 'n_steps': 85,\n",
       " 'n_episodes': 10}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = one_training_round(\n",
    "    env,\n",
    "    actor,\n",
    "    critic,\n",
    "    discriminator,\n",
    "    actor_optim,\n",
    "    critic_optim,\n",
    "    discriminator_optim,\n",
    "    encode,\n",
    "    num_actions,\n",
    "    X_e,\n",
    "    expert_records=None,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    ppo_clip=0.2,\n",
    "    epochs=4,\n",
    "    minibatch_size=512,\n",
    "    entropy_coeff=5e-3,\n",
    "    value_coeff=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    normalize_adv=True,\n",
    "    loss_type='bce',\n",
    "    gp_lambda=10.0,\n",
    "    d_updates=4,\n",
    "    d_minibatch_size=512,\n",
    "    use_gp=True,\n",
    "    instance_noise_std=0.0,\n",
    "    label_smoothing=0.1,\n",
    "    max_steps=num_steps,\n",
    "    num_episodes=train_eps,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320cae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "[005] R_env(m)=121.413  R_D(m)=0.699  π: L_actor=-0.020  V: L_critic=0.506  D: L=9.887  acc=0.512\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "[010] R_env(m)=124.381  R_D(m)=0.706  π: L_actor=-0.017  V: L_critic=0.292  D: L=8.351  acc=0.532\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "[015] R_env(m)=132.972  R_D(m)=0.724  π: L_actor=-0.022  V: L_critic=0.216  D: L=5.666  acc=0.490\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "[020] R_env(m)=162.193  R_D(m)=0.785  π: L_actor=-0.012  V: L_critic=0.198  D: L=2.540  acc=0.438\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n",
      "Epoch 1/4 completed.\n",
      "Epoch 2/4 completed.\n",
      "Epoch 3/4 completed.\n",
      "Epoch 4/4 completed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m dret_ma = deque(maxlen=\u001b[32m10\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs + \u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     stats = \u001b[43mone_training_round\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mactor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mactor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcritic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mactor_optim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mactor_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritic_optim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcritic_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator_optim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiscriminator_optim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_actions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_actions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_e\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_e\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.99\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgae_lambda\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mppo_clip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminibatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mentropy_coeff\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_coeff\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormalize_adv\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbce\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgp_lambda\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_updates\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_minibatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstance_noise_std\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_eps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     ret_ma.append(stats[\u001b[33m'\u001b[39m\u001b[33mavg_env_return\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     25\u001b[39m     dret_ma.append(stats[\u001b[33m'\u001b[39m\u001b[33mavg_D_reward\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eylam\\Desktop\\COMS4995 Causal Inference II\\causalrl\\imitation\\gym_gail\\causal_gail.py:593\u001b[39m, in \u001b[36mone_training_round\u001b[39m\u001b[34m(env, actor, critic, discriminator, actor_optim, critic_optim, discriminator_optim, encode, num_actions, X_e, expert_records, gamma, gae_lambda, ppo_clip, epochs, minibatch_size, entropy_coeff, value_coeff, max_grad_norm, normalize_adv, loss_type, gp_lambda, d_updates, d_minibatch_size, use_gp, instance_noise_std, label_smoothing, max_steps, num_episodes, seed)\u001b[39m\n\u001b[32m    590\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    591\u001b[39m     X_e = X_e.to(d_device, non_blocking=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m roll = \u001b[43mrollout_policy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcritic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_actions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    604\u001b[39m Z_pi = roll[\u001b[33m'\u001b[39m\u001b[33mZ\u001b[39m\u001b[33m'\u001b[39m].to(a_device, non_blocking=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    605\u001b[39m A_pi = roll[\u001b[33m'\u001b[39m\u001b[33mA\u001b[39m\u001b[33m'\u001b[39m].to(a_device, non_blocking=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eylam\\Desktop\\COMS4995 Causal Inference II\\causalrl\\imitation\\gym_gail\\causal_gail.py:172\u001b[39m, in \u001b[36mrollout_policy\u001b[39m\u001b[34m(env, actor, critic, encode, num_actions, max_steps, num_episodes, seed)\u001b[39m\n\u001b[32m    169\u001b[39m     value = critic(z).squeeze(\u001b[32m1\u001b[39m)\n\u001b[32m    171\u001b[39m a = \u001b[38;5;28mint\u001b[39m(action.item())\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m next_obs, r, terminated, truncated, _ = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_reward\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    173\u001b[39m done = terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[32m    174\u001b[39m reward += r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\COMS4995 Causal Inference II\\causalgym\\causal_gym\\core\\pch.py:68\u001b[39m, in \u001b[36mPCH.__getattribute__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     67\u001b[39m     \u001b[38;5;28mself\u001b[39m._permission_check(name)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mattr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\COMS4995 Causal Inference II\\causalgym\\causal_gym\\envs\\highway.py:593\u001b[39m, in \u001b[36mHighwayPCH.do\u001b[39m\u001b[34m(self, do_policy, show_reward)\u001b[39m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo\u001b[39m(\u001b[38;5;28mself\u001b[39m, do_policy, show_reward = \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    592\u001b[39m     action = do_policy(\u001b[38;5;28mself\u001b[39m.env.observation())\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m     o, r, term, trunc, info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_reward\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_reward\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    594\u001b[39m     info[\u001b[33m'\u001b[39m\u001b[33maction\u001b[39m\u001b[33m'\u001b[39m] = action\n\u001b[32m    595\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m o, r, term, trunc, info\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\COMS4995 Causal Inference II\\causalgym\\causal_gym\\envs\\highway.py:351\u001b[39m, in \u001b[36mHighwaySCM.step\u001b[39m\u001b[34m(self, action, show_reward)\u001b[39m\n\u001b[32m    348\u001b[39m A_t = \u001b[38;5;28mself\u001b[39m.A[\u001b[38;5;28mself\u001b[39m.t]\n\u001b[32m    349\u001b[39m B_t = \u001b[38;5;28mself\u001b[39m.B[\u001b[38;5;28mself\u001b[39m.t]\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m env_obs, _, terminated, _, env_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_env\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m Y_t = \u001b[38;5;28mself\u001b[39m._reward(X_t, D_t, A_t, B_t, U_t)\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._Y) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eylam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:393\u001b[39m, in \u001b[36mOrderEnforcing.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_reset:\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[33m\"\u001b[39m\u001b[33mCannot call env.step() before calling env.reset()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eylam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\core.py:327\u001b[39m, in \u001b[36mWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    324\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[32m    325\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    326\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eylam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:285\u001b[39m, in \u001b[36mPassiveEnvChecker.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m.env, action)\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eylam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\highway_env\\envs\\common\\abstract.py:240\u001b[39m, in \u001b[36mAbstractEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    236\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe road and vehicle must be initialized in the environment implementation\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    237\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28mself\u001b[39m.time += \u001b[32m1\u001b[39m / \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mpolicy_frequency\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_simulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m obs = \u001b[38;5;28mself\u001b[39m.observation_type.observe()\n\u001b[32m    243\u001b[39m reward = \u001b[38;5;28mself\u001b[39m._reward(action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eylam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\highway_env\\envs\\common\\abstract.py:271\u001b[39m, in \u001b[36mAbstractEnv._simulate\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    260\u001b[39m     action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    261\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mmanual_control\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m     == \u001b[32m0\u001b[39m\n\u001b[32m    268\u001b[39m ):\n\u001b[32m    269\u001b[39m     \u001b[38;5;28mself\u001b[39m.action_type.act(action)\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroad\u001b[49m\u001b[43m.\u001b[49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[38;5;28mself\u001b[39m.road.step(\u001b[32m1\u001b[39m / \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33msimulation_frequency\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    273\u001b[39m \u001b[38;5;28mself\u001b[39m.steps += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eylam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\highway_env\\road\\road.py:464\u001b[39m, in \u001b[36mRoad.act\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    462\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Decide the actions of each entity on the road.\"\"\"\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m vehicle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vehicles:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[43mvehicle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eylam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\highway_env\\vehicle\\behavior.py:108\u001b[39m, in \u001b[36mIDMVehicle.act\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28mself\u001b[39m.follow_road()\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.enable_lane_change:\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchange_lane_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m action[\u001b[33m\"\u001b[39m\u001b[33msteering\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.steering_control(\u001b[38;5;28mself\u001b[39m.target_lane_index)\n\u001b[32m    110\u001b[39m action[\u001b[33m\"\u001b[39m\u001b[33msteering\u001b[39m\u001b[33m\"\u001b[39m] = np.clip(\n\u001b[32m    111\u001b[39m     action[\u001b[33m\"\u001b[39m\u001b[33msteering\u001b[39m\u001b[33m\"\u001b[39m], -\u001b[38;5;28mself\u001b[39m.MAX_STEERING_ANGLE, \u001b[38;5;28mself\u001b[39m.MAX_STEERING_ANGLE\n\u001b[32m    112\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eylam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\highway_env\\vehicle\\behavior.py:262\u001b[39m, in \u001b[36mIDMVehicle.change_lane_policy\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    261\u001b[39m \u001b[38;5;66;03m# Does the MOBIL model recommend a lane change?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmobil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlane_index\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    263\u001b[39m     \u001b[38;5;28mself\u001b[39m.target_lane_index = lane_index\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eylam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\highway_env\\vehicle\\behavior.py:277\u001b[39m, in \u001b[36mIDMVehicle.mobil\u001b[39m\u001b[34m(self, lane_index)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    267\u001b[39m \u001b[33;03mMOBIL lane change model: Minimizing Overall Braking Induced by a Lane change\u001b[39;00m\n\u001b[32m    268\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m \u001b[33;03m:return: whether the lane change should be performed\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# Is the maneuver unsafe for the new following vehicle?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m new_preceding, new_following = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroad\u001b[49m\u001b[43m.\u001b[49m\u001b[43mneighbour_vehicles\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlane_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m new_following_a = \u001b[38;5;28mself\u001b[39m.acceleration(\n\u001b[32m    279\u001b[39m     ego_vehicle=new_following, front_vehicle=new_preceding\n\u001b[32m    280\u001b[39m )\n\u001b[32m    281\u001b[39m new_following_pred_a = \u001b[38;5;28mself\u001b[39m.acceleration(\n\u001b[32m    282\u001b[39m     ego_vehicle=new_following, front_vehicle=\u001b[38;5;28mself\u001b[39m\n\u001b[32m    283\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eylam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\highway_env\\road\\road.py:504\u001b[39m, in \u001b[36mRoad.neighbour_vehicles\u001b[39m\u001b[34m(self, vehicle, lane_index)\u001b[39m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vehicles + \u001b[38;5;28mself\u001b[39m.objects:\n\u001b[32m    500\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vehicle \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    501\u001b[39m         v, Landmark\n\u001b[32m    502\u001b[39m     ):  \u001b[38;5;66;03m# self.network.is_connected_road(v.lane_index,\u001b[39;00m\n\u001b[32m    503\u001b[39m         \u001b[38;5;66;03m# lane_index, same_lane=True):\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m         s_v, lat_v = \u001b[43mlane\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlocal_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lane.on_lane(v.position, s_v, lat_v, margin=\u001b[32m1\u001b[39m):\n\u001b[32m    506\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eylam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\highway_env\\road\\lane.py:211\u001b[39m, in \u001b[36mStraightLane.local_coordinates\u001b[39m\u001b[34m(self, position)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlocal_coordinates\u001b[39m(\u001b[38;5;28mself\u001b[39m, position: np.ndarray) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    210\u001b[39m     delta = position - \u001b[38;5;28mself\u001b[39m.start\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     longitudinal = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m     lateral = np.dot(delta, \u001b[38;5;28mself\u001b[39m.direction_lateral)\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(longitudinal), \u001b[38;5;28mfloat\u001b[39m(lateral)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "epochs = 120\n",
    "log_every = 5\n",
    "ret_ma = deque(maxlen=20)\n",
    "dret_ma = deque(maxlen=20)\n",
    "\n",
    "for it in range(1, epochs + 1):\n",
    "    stats = one_training_round(\n",
    "        env=env,\n",
    "        actor=actor, critic=critic, discriminator=discriminator,\n",
    "        actor_optim=actor_optim, critic_optim=critic_optim, discriminator_optim=discriminator_optim,\n",
    "        encode=encode, num_actions=num_actions,\n",
    "        X_e=X_e,\n",
    "        gamma=0.99, gae_lambda=0.95,\n",
    "        ppo_clip=0.2, epochs=4, minibatch_size=512,\n",
    "        entropy_coeff=5e-3, value_coeff=0.5, max_grad_norm=0.5,\n",
    "        normalize_adv=True,\n",
    "        loss_type='bce',\n",
    "        gp_lambda=10.0, d_updates=4, d_minibatch_size=512, use_gp=True,\n",
    "        instance_noise_std=0.0, label_smoothing=0.1,\n",
    "        max_steps=num_steps, num_episodes=train_eps,\n",
    "        seed=seed + it\n",
    "    )\n",
    "\n",
    "    ret_ma.append(stats['avg_env_return'])\n",
    "    dret_ma.append(stats['avg_D_reward'])\n",
    "\n",
    "    if it % log_every == 0:\n",
    "        print(\n",
    "            f\"[{it:03d}] \"\n",
    "            f\"R_env(m)={np.mean(ret_ma):.3f}  \"\n",
    "            f\"R_D(m)={np.mean(dret_ma):.3f}  \"\n",
    "            f\"π: L_actor={stats['ppo_actor_loss']:.3f}  \"\n",
    "            f\"V: L_critic={stats['ppo_critic_loss']:.3f}  \"\n",
    "            f\"D: L={stats['D_loss']:.3f}  acc={stats['D_accuracy']:.3f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb26b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_policy(env, actor, encode, num_episodes=6, max_steps=num_steps, seed=None):\n",
    "    actor.eval()\n",
    "    returns = []\n",
    "\n",
    "    for e in range(num_episodes):\n",
    "        obs, _ = env.reset(seed=seed + e)\n",
    "        t, done, ret = 0, False, 0.0\n",
    "\n",
    "        while not done and t < max_steps:\n",
    "            z = torch.from_numpy(encode(obs, t)).float().unsqueeze(0).to(next(actor.parameters()).device)\n",
    "            a, _, _ = actor.act(z, deterministic=True)\n",
    "            obs, r, terminated, truncated, _ = env.do(lambda _: int(a.item()), show_reward=True)\n",
    "\n",
    "            ret += r\n",
    "            t += 1\n",
    "            done = terminated or truncated\n",
    "\n",
    "        returns.append(ret)\n",
    "\n",
    "    return float(np.mean(returns)), returns\n",
    "\n",
    "eval_policy(env, actor, encode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
