{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b07664b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n",
      "/home/et2842/miniconda3/envs/causalenv/lib/python3.11/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from causal_gym import AntMazePCH\n",
    "from causal_rl.algo.imitation.imitate import *\n",
    "from causal_rl.algo.imitation.finetune import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e47fff06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5949c760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x77ee44006a70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_steps = 1000\n",
    "seed = 0\n",
    "hidden_dims = {'F'}\n",
    "lookback = 1\n",
    "train_eps = 1000\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ea61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_env = AntMazePCH(num_steps=num_steps, hidden_dims=set(), seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac1e51bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save time; conceptually the same\n",
    "small_steps = lookback + 1\n",
    "small_env = AntMazePCH(num_steps=small_steps, hidden_dims=hidden_dims, seed=seed)\n",
    "G = parse_graph(small_env.get_graph)\n",
    "X_small = {f'X{t}' for t in range(small_steps)}\n",
    "Y = f'Y{small_steps}'\n",
    "\n",
    "# G = parse_graph(env.get_graph)\n",
    "X = {f'X{t}' for t in range(num_steps)}\n",
    "# Y = f'Y{num_steps}'\n",
    "obs_prefix = expert_env.env.observed_unobserved_vars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3324c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_sets = find_sequential_pi_backdoor(G, X_small, Y, obs_prefix)\n",
    "\n",
    "base_step = small_steps - 1\n",
    "base_Z_set = Z_sets[f'X{base_step}']\n",
    "\n",
    "for i in range(base_step + 1, num_steps):\n",
    "    updated_base_Z_set = set()\n",
    "    for v in base_Z_set:\n",
    "        updated_base_Z_set.add(f'{v[0]}{int(v[1:]) + i - lookback}')\n",
    "\n",
    "    Z_sets[f'X{i}'] = updated_base_Z_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95c33186",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_Z_sets = {}\n",
    "for Xi in X:\n",
    "    i = int(Xi[1:])\n",
    "    cond = set()\n",
    "\n",
    "    for j in range(i+1):\n",
    "        cond.update({f'{o}{j}' for o in list(set(obs_prefix) - {'X'})})\n",
    "\n",
    "    for j in range(i):\n",
    "        cond.add(f'X{j}')\n",
    "    naive_Z_sets[Xi] = cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa4c9599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_527570/2542572679.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL_PATH, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# load expert\n",
    "MODEL_PATH = '/home/et2842/causal/causalrl/models/antmaze_expert_finetuned.pt'\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "\n",
    "# Rebuild the model with the same architecture\n",
    "action_bounds = (checkpoint['action_bounds_low'], checkpoint['action_bounds_high'])\n",
    "\n",
    "expert = ContinuousPolicyNN(\n",
    "    input_dim=checkpoint['input_dim'],\n",
    "    action_dim=checkpoint['num_actions'],\n",
    "    hidden_dim=checkpoint['hidden_dim'],\n",
    "    num_blocks=checkpoint['num_blocks'],\n",
    "    dropout=checkpoint['dropout'],\n",
    "    layernorm=checkpoint['layernorm'],\n",
    "    final_tanh=checkpoint['final_tanh'],\n",
    "    action_bounds=action_bounds,\n",
    ").to(device)\n",
    "\n",
    "expert.load_state_dict(checkpoint['state_dict'])\n",
    "expert.eval()\n",
    "\n",
    "slots = checkpoint['slots']\n",
    "Z_trim = checkpoint['Z_trim']\n",
    "dims = checkpoint['dims']\n",
    "lookback = checkpoint['lookback']\n",
    "\n",
    "state_dim = checkpoint['input_dim']\n",
    "state_dim\n",
    "\n",
    "def make_ft_policies_with_F(model, slots, Z_trim, device, num_steps, extra_vars):\n",
    "    policies = {}\n",
    "    for t in range(num_steps):\n",
    "        def pi_t(obs, t=t):\n",
    "            state = build_state_feature(obs, t, Z_trim, slots, device, extra_vars=extra_vars)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                action = model(state).squeeze(0).cpu().numpy().astype(np.float32)\n",
    "\n",
    "            return action\n",
    "        \n",
    "        policies[f'X{t}'] = pi_t\n",
    "\n",
    "    return policies\n",
    "\n",
    "expert_policies = make_ft_policies_with_F(\n",
    "    expert,\n",
    "    slots=slots,\n",
    "    Z_trim=Z_trim,\n",
    "    device=device,\n",
    "    num_steps=num_steps,\n",
    "    extra_vars={'F'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfac22cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting episode 1/1000...\n",
      "  Episode 1 ended at step 271 (terminated: True, truncated: False).\n",
      "Starting episode 2/1000...\n",
      "  Episode 2 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 3/1000...\n",
      "  Episode 3 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 4/1000...\n",
      "  Episode 4 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 5/1000...\n",
      "  Episode 5 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 6/1000...\n",
      "  Episode 6 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 7/1000...\n",
      "  Episode 7 ended at step 263 (terminated: True, truncated: False).\n",
      "Starting episode 8/1000...\n",
      "  Episode 8 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 9/1000...\n",
      "  Episode 9 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 10/1000...\n",
      "  Episode 10 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 11/1000...\n",
      "  Episode 11 ended at step 488 (terminated: True, truncated: False).\n",
      "Starting episode 12/1000...\n",
      "  Episode 12 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 13/1000...\n",
      "  Episode 13 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 14/1000...\n",
      "  Episode 14 ended at step 315 (terminated: True, truncated: False).\n",
      "Starting episode 15/1000...\n",
      "  Episode 15 ended at step 521 (terminated: True, truncated: False).\n",
      "Starting episode 16/1000...\n",
      "  Episode 16 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 17/1000...\n",
      "  Episode 17 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 18/1000...\n",
      "  Episode 18 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 19/1000...\n",
      "  Episode 19 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 20/1000...\n",
      "  Episode 20 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 21/1000...\n",
      "  Episode 21 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 22/1000...\n",
      "  Episode 22 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 23/1000...\n",
      "  Episode 23 ended at step 481 (terminated: True, truncated: False).\n",
      "Starting episode 24/1000...\n",
      "  Episode 24 ended at step 459 (terminated: True, truncated: False).\n",
      "Starting episode 25/1000...\n",
      "  Episode 25 ended at step 354 (terminated: True, truncated: False).\n",
      "Starting episode 26/1000...\n",
      "  Episode 26 ended at step 279 (terminated: True, truncated: False).\n",
      "Starting episode 27/1000...\n",
      "  Episode 27 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 28/1000...\n",
      "  Episode 28 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 29/1000...\n",
      "  Episode 29 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 30/1000...\n",
      "  Episode 30 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 31/1000...\n",
      "  Episode 31 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 32/1000...\n",
      "  Episode 32 ended at step 393 (terminated: True, truncated: False).\n",
      "Starting episode 33/1000...\n",
      "  Episode 33 ended at step 412 (terminated: True, truncated: False).\n",
      "Starting episode 34/1000...\n",
      "  Episode 34 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 35/1000...\n",
      "  Episode 35 ended at step 313 (terminated: True, truncated: False).\n",
      "Starting episode 36/1000...\n",
      "  Episode 36 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 37/1000...\n",
      "  Episode 37 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 38/1000...\n",
      "  Episode 38 ended at step 420 (terminated: True, truncated: False).\n",
      "Starting episode 39/1000...\n",
      "  Episode 39 ended at step 326 (terminated: True, truncated: False).\n",
      "Starting episode 40/1000...\n",
      "  Episode 40 ended at step 296 (terminated: True, truncated: False).\n",
      "Starting episode 41/1000...\n",
      "  Episode 41 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 42/1000...\n",
      "  Episode 42 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 43/1000...\n",
      "  Episode 43 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 44/1000...\n",
      "  Episode 44 ended at step 325 (terminated: True, truncated: False).\n",
      "Starting episode 45/1000...\n",
      "  Episode 45 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 46/1000...\n",
      "  Episode 46 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 47/1000...\n",
      "  Episode 47 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 48/1000...\n",
      "  Episode 48 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 49/1000...\n",
      "  Episode 49 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 50/1000...\n",
      "  Episode 50 ended at step 268 (terminated: True, truncated: False).\n",
      "Starting episode 51/1000...\n",
      "  Episode 51 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 52/1000...\n",
      "  Episode 52 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 53/1000...\n",
      "  Episode 53 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 54/1000...\n",
      "  Episode 54 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 55/1000...\n",
      "  Episode 55 ended at step 358 (terminated: True, truncated: False).\n",
      "Starting episode 56/1000...\n",
      "  Episode 56 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 57/1000...\n",
      "  Episode 57 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 58/1000...\n",
      "  Episode 58 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 59/1000...\n",
      "  Episode 59 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 60/1000...\n",
      "  Episode 60 ended at step 271 (terminated: True, truncated: False).\n",
      "Starting episode 61/1000...\n",
      "  Episode 61 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 62/1000...\n",
      "  Episode 62 ended at step 454 (terminated: True, truncated: False).\n",
      "Starting episode 63/1000...\n",
      "  Episode 63 ended at step 349 (terminated: True, truncated: False).\n",
      "Starting episode 64/1000...\n",
      "  Episode 64 ended at step 370 (terminated: True, truncated: False).\n",
      "Starting episode 65/1000...\n",
      "  Episode 65 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 66/1000...\n",
      "  Episode 66 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 67/1000...\n",
      "  Episode 67 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 68/1000...\n",
      "  Episode 68 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 69/1000...\n",
      "  Episode 69 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 70/1000...\n",
      "  Episode 70 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 71/1000...\n",
      "  Episode 71 ended at step 467 (terminated: True, truncated: False).\n",
      "Starting episode 72/1000...\n",
      "  Episode 72 ended at step 352 (terminated: True, truncated: False).\n",
      "Starting episode 73/1000...\n",
      "  Episode 73 ended at step 275 (terminated: True, truncated: False).\n",
      "Starting episode 74/1000...\n",
      "  Episode 74 ended at step 305 (terminated: True, truncated: False).\n",
      "Starting episode 75/1000...\n",
      "  Episode 75 ended at step 363 (terminated: True, truncated: False).\n",
      "Starting episode 76/1000...\n",
      "  Episode 76 ended at step 427 (terminated: True, truncated: False).\n",
      "Starting episode 77/1000...\n",
      "  Episode 77 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 78/1000...\n",
      "  Episode 78 ended at step 269 (terminated: True, truncated: False).\n",
      "Starting episode 79/1000...\n",
      "  Episode 79 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 80/1000...\n",
      "  Episode 80 ended at step 350 (terminated: True, truncated: False).\n",
      "Starting episode 81/1000...\n",
      "  Episode 81 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 82/1000...\n",
      "  Episode 82 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 83/1000...\n",
      "  Episode 83 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 84/1000...\n",
      "  Episode 84 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 85/1000...\n",
      "  Episode 85 ended at step 296 (terminated: True, truncated: False).\n",
      "Starting episode 86/1000...\n",
      "  Episode 86 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 87/1000...\n",
      "  Episode 87 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 88/1000...\n",
      "  Episode 88 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 89/1000...\n",
      "  Episode 89 ended at step 367 (terminated: True, truncated: False).\n",
      "Starting episode 90/1000...\n",
      "  Episode 90 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 91/1000...\n",
      "  Episode 91 ended at step 474 (terminated: True, truncated: False).\n",
      "Starting episode 92/1000...\n",
      "  Episode 92 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 93/1000...\n",
      "  Episode 93 ended at step 332 (terminated: True, truncated: False).\n",
      "Starting episode 94/1000...\n",
      "  Episode 94 ended at step 302 (terminated: True, truncated: False).\n",
      "Starting episode 95/1000...\n",
      "  Episode 95 ended at step 1000 (terminated: False, truncated: True).\n",
      "Starting episode 96/1000...\n",
      "  Episode 96 ended at step 362 (terminated: True, truncated: False).\n",
      "Starting episode 97/1000...\n",
      "  Episode 97 ended at step 313 (terminated: True, truncated: False).\n",
      "Starting episode 98/1000...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m records = \u001b[43mcollect_imitator_trajectories\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexpert_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexpert_policies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_eps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/causal/causalrl/causal_rl/algo/imitation/imitate.py:597\u001b[39m, in \u001b[36mcollect_imitator_trajectories\u001b[39m\u001b[34m(env, policies, num_episodes, max_steps, seed, reset_seed_fn, show_progress)\u001b[39m\n\u001b[32m    592\u001b[39m obs, _ = env.reset(seed=ep_seed)\n\u001b[32m    594\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_steps):\n\u001b[32m    595\u001b[39m     \u001b[38;5;66;03m# select action using the appropriate per-step policy\u001b[39;00m\n\u001b[32m    596\u001b[39m     \u001b[38;5;66;03m# (keys should match those used in eval_policy)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m597\u001b[39m     action = \u001b[43mpolicies\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstep\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    599\u001b[39m     obs, reward, terminated, truncated, info = env.do(\n\u001b[32m    600\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x: action,\n\u001b[32m    601\u001b[39m         show_reward=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    602\u001b[39m     )\n\u001b[32m    604\u001b[39m     action = info[\u001b[33m'\u001b[39m\u001b[33maction\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mmake_ft_policies_with_F.<locals>.pi_t\u001b[39m\u001b[34m(obs, t)\u001b[39m\n\u001b[32m     34\u001b[39m state = build_state_feature(obs, t, Z_trim, slots, device, extra_vars=extra_vars)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     action = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m.squeeze(\u001b[32m0\u001b[39m).cpu().numpy().astype(np.float32)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m action\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/causalenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/causalenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/causal/causalrl/causal_rl/algo/imitation/imitate.py:347\u001b[39m, in \u001b[36mContinuousPolicyNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor) -> torch.Tensor:\n\u001b[32m    346\u001b[39m     \u001b[38;5;66;03m# x: (B, input_dim)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m     h = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks:\n\u001b[32m    349\u001b[39m         h = blk(h)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/causalenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/causalenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/causalenv/lib/python3.11/site-packages/torch/nn/modules/linear.py:117\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.linear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m.weight, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/causalenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1716\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1707\u001b[39m         \u001b[38;5;28mself\u001b[39m._backward_pre_hooks = OrderedDict()\n\u001b[32m   1709\u001b[39m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[32m   1710\u001b[39m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[32m   1711\u001b[39m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1714\u001b[39m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[32m   1715\u001b[39m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1716\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Any:\n\u001b[32m   1717\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m:\n\u001b[32m   1718\u001b[39m         _parameters = \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m[\u001b[33m'\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "records = collect_imitator_trajectories(\n",
    "    expert_env,\n",
    "    expert_policies,\n",
    "    num_episodes=train_eps,\n",
    "    max_steps=num_steps,\n",
    "    seed=seed,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/et2842/causal/expert_traj.pkl', 'wb') as f:\n",
    "    pickle.dump(records, f)\n",
    "\n",
    "print(f'saved {len(records)} trajectories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81bc851",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/et2842/causal/expert_traj.pkl', 'rb') as f:\n",
    "    records = pickle.load(f)\n",
    "\n",
    "print(f'loaded {len(records)} trajectories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7aa378",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "lr = 3e-4\n",
    "batch_size = 2048\n",
    "patience = 15\n",
    "num_blocks = 4\n",
    "epochs = 100\n",
    "dropout = 0.0\n",
    "\n",
    "dims = {\n",
    "    'P': 3,\n",
    "    'O': 4,\n",
    "    'A': 8,\n",
    "    'L': 3,\n",
    "    'T': 3,\n",
    "    'J': 8,\n",
    "    'F': 2,\n",
    "    'W': 1,\n",
    "    'X': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fa780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = AntMazePCH(num_steps=num_steps, hidden_dims=hidden_dims, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb5bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_model, causal_slots, causal_Z_trim = train_single_policy_long_horizon(\n",
    "    records,\n",
    "    Z_sets,\n",
    "    dims=dims,\n",
    "    epochs=epochs,\n",
    "    include_vars=obs_prefix,\n",
    "    lookback=lookback,\n",
    "    continuous=True,\n",
    "    num_actions = env.action_space.shape[0],\n",
    "    hidden_dim=hidden_size,\n",
    "    num_blocks=num_blocks,\n",
    "    dropout=dropout,\n",
    "    lr=lr,\n",
    "    batch_size=batch_size,\n",
    "    patience=patience,\n",
    "    device=device,\n",
    "    seed=seed,\n",
    "    action_bounds=(env.action_space.low, env.action_space.high)\n",
    ")\n",
    "\n",
    "causal_policy = shared_policy_fn_long_horizon(causal_model, causal_slots, causal_Z_trim, continuous=True, device=device)\n",
    "causal_policies = make_shared_policy_dict(causal_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed7f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_model, naive_slots, naive_Z_trim = train_single_policy_long_horizon(\n",
    "    records,\n",
    "    naive_Z_sets,\n",
    "    dims=dims,\n",
    "    epochs=epochs,\n",
    "    include_vars=obs_prefix,\n",
    "    lookback=lookback,\n",
    "    continuous=True,\n",
    "    num_actions = env.action_space.shape[0],\n",
    "    hidden_dim=hidden_size,\n",
    "    num_blocks=num_blocks,\n",
    "    dropout=dropout,\n",
    "    lr=lr,\n",
    "    batch_size=batch_size,\n",
    "    patience=patience,\n",
    "    device=device,\n",
    "    seed=seed,\n",
    "    action_bounds=(env.action_space.low, env.action_space.high)\n",
    ")\n",
    "\n",
    "naive_policy = shared_policy_fn_long_horizon(naive_model, naive_slots, naive_Z_trim, continuous=True, device=device)\n",
    "naive_policies = make_shared_policy_dict(naive_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dfb194",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_episode_rewards = defaultdict(float)\n",
    "for rec in records:\n",
    "    ep = rec['episode']\n",
    "    expert_episode_rewards[ep] += float(rec['reward'])\n",
    "\n",
    "num_eps = len(expert_episode_rewards)\n",
    "expert_rewards = [expert_episode_rewards[e] for e in range(num_eps)]\n",
    "\n",
    "causal_records = collect_imitator_trajectories(env, causal_policies, num_episodes=num_eps, max_steps=num_steps, seed=seed)\n",
    "causal_episode_rewards = defaultdict(float)\n",
    "for rec in causal_records:\n",
    "    ep = rec['episode']\n",
    "    causal_episode_rewards[ep] += float(rec['reward'])\n",
    "\n",
    "causal_rewards = [causal_episode_rewards[e] for e in range(num_eps)]\n",
    "\n",
    "naive_records = collect_imitator_trajectories(env, naive_policies, num_episodes=num_eps, max_steps=num_steps, seed=seed)\n",
    "naive_episode_rewards = defaultdict(float)\n",
    "for rec in naive_records:\n",
    "    ep = rec['episode']\n",
    "    naive_episode_rewards[ep] += float(rec['reward'])\n",
    "\n",
    "naive_rewards = [naive_episode_rewards[e] for e in range(num_eps)]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(expert_rewards, label='Expert')\n",
    "plt.plot(causal_rewards, label='Causal BC')\n",
    "plt.plot(naive_rewards, label='Naive BC')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Final Cumulative Reward')\n",
    "plt.title('Comparison of Expert vs. Causal vs. Naive Returns')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bf6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(expert_rewards)/num_eps, sum(causal_rewards)/num_eps, sum(naive_rewards)/num_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad465c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib import cm\n",
    "\n",
    "def get_episode_xy_from_records(records, episode_id: int):\n",
    "    '''\n",
    "    records: list of dicts from collect_expert_trajectories(...)\n",
    "    episode_id: which episode to extract\n",
    "\n",
    "    Returns:\n",
    "        xs, ys : np.ndarray of shape (T,)\n",
    "    '''\n",
    "    # Filter records for that episode, sorted by step\n",
    "    ep = [r for r in records if r['episode'] == episode_id]\n",
    "    ep = sorted(ep, key=lambda r: r['step'])\n",
    "\n",
    "    xs, ys = [], []\n",
    "    for r in ep:\n",
    "        # r['info']['hidden_obs']['P'] is a *history* list; last entry is current position\n",
    "        pos = r['obs']['P'][-1]   # shape (3,)\n",
    "        xs.append(pos[0])\n",
    "        ys.append(pos[1])\n",
    "\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "def plot_ant_trajectory_xy(records, episode_id: int = 0, ax=None, title_prefix='AntMaze'):\n",
    "    '''\n",
    "    Visualize the ant's 2D trajectory (x, y) for a single episode.\n",
    "\n",
    "    - Path is colored by time (early=dark, late=bright).\n",
    "    - Start and end are annotated.\n",
    "    - Small arrows show direction every few steps.\n",
    "    '''\n",
    "    xs, ys = get_episode_xy_from_records(records, episode_id)\n",
    "    T = len(xs)\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "\n",
    "    # Build a colored line collection for the path\n",
    "    points = np.array([xs, ys]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "\n",
    "    # Time as color (0..1)\n",
    "    t_norm = np.linspace(0, 1, T-1)\n",
    "    lc = LineCollection(segments, cmap='viridis', norm=plt.Normalize(0, 1))\n",
    "    lc.set_array(t_norm)\n",
    "    lc.set_linewidth(2.5)\n",
    "    ax.add_collection(lc)\n",
    "\n",
    "    # Start and end markers\n",
    "    ax.scatter(xs[0], xs[0], alpha=0)  # dummy to keep colors aligned if needed\n",
    "    ax.scatter(xs[0], ys[0], s=80, c='green', marker='o', edgecolors='black', label='Start')\n",
    "    ax.scatter(xs[-1], ys[-1], s=80, c='red', marker='X', edgecolors='black', label='End')\n",
    "\n",
    "    # Small arrows every N steps to show direction\n",
    "    step = max(1, T // 30)  # about ~30 arrows max\n",
    "    for i in range(0, T-1, step):\n",
    "        dx = xs[i+1] - xs[i]\n",
    "        dy = ys[i+1] - ys[i]\n",
    "        ax.arrow(xs[i], ys[i], dx, dy,\n",
    "                 length_includes_head=True,\n",
    "                 head_width=0.2,\n",
    "                 head_length=0.4,\n",
    "                 alpha=0.6)\n",
    "\n",
    "    # Colorbar for time\n",
    "    cbar = fig.colorbar(lc, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Time (normalized)')\n",
    "\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    ax.set_xlabel('x position')\n",
    "    ax.set_ylabel('y position')\n",
    "    ax.set_title(f'{title_prefix} - Episode {episode_id} trajectory')\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "fig, ax = plot_ant_trajectory_xy(records, episode_id=0, title_prefix='Expert AntMaze')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ce4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_ant_trajectory_xy(causal_records, episode_id=0, title_prefix='Causal AntMaze')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68603908",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_ant_trajectory_xy(naive_records, episode_id=0, title_prefix='Naive AntMaze')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
