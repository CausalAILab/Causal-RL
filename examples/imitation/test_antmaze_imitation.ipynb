{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b07664b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n",
      "/home/et2842/miniconda3/envs/causalenv/lib/python3.11/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from causal_gym import AntMazePCH\n",
    "from causal_rl.algo.imitation.imitate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e47fff06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5949c760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7989c8194430>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_steps = 100\n",
    "seed = 0\n",
    "hidden_dims = {}\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ea61d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1101"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = AntMazePCH(num_steps=num_steps, hidden_dims=hidden_dims, seed=seed)\n",
    "train_eps = env.expert.num_eps\n",
    "train_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac1e51bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = parse_graph(env.get_graph)\n",
    "X = {f'X{t}' for t in range(num_steps)}\n",
    "Y = f'Y{num_steps}'\n",
    "obs_prefix = env.env.observed_unobserved_vars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3324c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_sets = find_sequential_pi_backdoor(G, X, Y, obs_prefix)\n",
    "# Z_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfac22cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = collect_expert_trajectories(\n",
    "    env,\n",
    "    num_episodes=train_eps,\n",
    "    max_steps=num_steps,\n",
    "    behavioral_policy=None,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95c33186",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_Z_sets = {}\n",
    "for Xi in X:\n",
    "    i = int(Xi[1:])\n",
    "    cond = set()\n",
    "\n",
    "    for j in range(i+1):\n",
    "        cond.update({f'{o}{j}' for o in list(set(obs_prefix) - {'X'})})\n",
    "\n",
    "    for j in range(i):\n",
    "        cond.add(f'X{j}')\n",
    "    naive_Z_sets[Xi] = cond\n",
    "\n",
    "# naive_Z_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e75479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim Z-sets to only include lookback of 5 steps\n",
    "def trim_Z_sets(Z_sets, lookback=5):\n",
    "    trimmed_Z_sets = {}\n",
    "    for Xi, cond_vars in Z_sets.items():\n",
    "        i = int(Xi[1:])\n",
    "        \n",
    "        if i < lookback:\n",
    "            trimmed_Z_sets[Xi] = cond_vars.copy()\n",
    "            continue\n",
    "\n",
    "        min_t = i - lookback\n",
    "        keep_vars = set()\n",
    "\n",
    "        for var in cond_vars:\n",
    "            step = int(var[1:])\n",
    "            if step >= min_t:\n",
    "                keep_vars.add(var)\n",
    "        trimmed_Z_sets[Xi] = keep_vars\n",
    "    return trimmed_Z_sets\n",
    "\n",
    "Z_sets = trim_Z_sets(Z_sets, lookback=5)\n",
    "naive_Z_sets = trim_Z_sets(naive_Z_sets, lookback=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb5bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "causal_policies = train_policies(env, records, Z_sets, lr=3e-4, batch_size=512, seed=seed, patience=20, continuous=True, hidden_dim=hidden_size, device=device)\n",
    "naive_policies = train_policies(env, records, naive_Z_sets, lr=3e-4, batch_size=512, seed=seed, patience=20, continuous=True, hidden_dim=hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dfb194",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_rewards = defaultdict(float)\n",
    "for rec in records:\n",
    "    ep = rec['episode']\n",
    "    episode_rewards[ep] = rec['info']['Y'][-1]\n",
    "\n",
    "num_eps = len(episode_rewards)\n",
    "\n",
    "expert_rewards = [episode_rewards[e] for e in range(num_eps)]\n",
    "\n",
    "causal_returns = eval_policy(env, causal_policies, num_episodes=num_eps, seed=seed, device=device)\n",
    "naive_returns = eval_policy(env, naive_policies, num_episodes=num_eps, seed=seed, device=device)\n",
    "\n",
    "causal_rewards = [ep['Y'][-1] for ep in causal_returns]\n",
    "naive_rewards = [ep['Y'][-1] for ep in naive_returns]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(expert_rewards, label='Expert (behavioral)')\n",
    "plt.plot(causal_rewards, label='Causal imitation')\n",
    "plt.plot(naive_rewards, label='Naive behavior control')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Final Cumulative Reward')\n",
    "plt.title('Comparison of Expert vs. Causal vs. Naive Returns')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d3b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "bins = 20  # number of histogram bins\n",
    "\n",
    "expert_mean = np.mean(expert_rewards)\n",
    "causal_mean = sum(causal_rewards) / len(causal_rewards)\n",
    "naive_mean = sum(naive_rewards) / len(naive_rewards)\n",
    "\n",
    "# plot histograms for causal and naive\n",
    "plt.hist(causal_rewards, bins=bins, alpha=0.6, label=f'Causal Imitation ({causal_mean:.1f})')\n",
    "plt.hist(naive_rewards,  bins=bins, alpha=0.6, label=f'Naive Baseline ({naive_mean:.1f})')\n",
    "\n",
    "# compute and plot expert mean as a vertical line\n",
    "plt.axvline(expert_mean, color='black', linestyle='--', linewidth=2, label=f'Expert Mean ({expert_mean:.1f})')\n",
    "\n",
    "plt.xlabel('Final Cumulative Reward')\n",
    "plt.ylabel('Number of Episodes')\n",
    "plt.title('Episode Return Distributions')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ac0f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_accuracy(records, policies):\n",
    "    total, correct = 0, 0\n",
    "    per_step = defaultdict(lambda: {'corr':0, 'total':0})\n",
    "\n",
    "    for r in records:\n",
    "        t = r['step']\n",
    "        key = f'X{t}'\n",
    "        if key not in policies:\n",
    "            # no policy for this step—skip or count as incorrect\n",
    "            continue\n",
    "        pi_t = policies[key]\n",
    "        pred = pi_t(r['obs'])\n",
    "        true = r['action']\n",
    "\n",
    "        per_step[t]['total']  += 1\n",
    "        per_step[t]['corr']   += int(pred == true)\n",
    "        total   += 1\n",
    "        correct += int(pred == true)\n",
    "\n",
    "    overall_acc = correct / total if total else float('nan')\n",
    "    print(f\"Overall accuracy: {overall_acc*100:.2f}% ({correct}/{total})\")\n",
    "\n",
    "    print(\"Per-step accuracy:\")\n",
    "    for t in sorted(per_step):\n",
    "        ts = per_step[t]\n",
    "        acc = ts['corr']/ts['total']\n",
    "        print(f\"  step {t}: {acc*100:.2f}% ({ts['corr']}/{ts['total']})\")\n",
    "\n",
    "    print()\n",
    "    return overall_acc, per_step\n",
    "\n",
    "# Example usage:\n",
    "ci_acc, ci_step_acc = policy_accuracy(records, causal_policies)\n",
    "bc_acc, bc_step_acc = policy_accuracy(records, naive_policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a138e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare label and display names\n",
    "n_actions = env.env.action_space.n\n",
    "labels = list(range(n_actions))\n",
    "action_names = list(env.env.unwrapped.action_type.actions.keys())\n",
    "\n",
    "# Gather true actions once\n",
    "y_true = []\n",
    "for r in records:\n",
    "    y_true.append(r['action'])\n",
    "\n",
    "# Gather predictions for causal and naive\n",
    "y_pred_causal = []\n",
    "y_pred_naive  = []\n",
    "for r in records:\n",
    "    t = r['step']\n",
    "    key = f'X{t}'\n",
    "    # causal\n",
    "    if key in causal_policies:\n",
    "        y_pred_causal.append(causal_policies[key](r['obs']))\n",
    "    else:\n",
    "        y_pred_causal.append(-1)  # or some placeholder\n",
    "    # naive\n",
    "    if key in naive_policies:\n",
    "        y_pred_naive.append(naive_policies[key](r['obs']))\n",
    "    else:\n",
    "        y_pred_naive.append(-1)\n",
    "\n",
    "# Compute confusion matrices (we’ll ignore the placeholder label -1)\n",
    "cm_causal = confusion_matrix(y_true, y_pred_causal, labels=labels)\n",
    "cm_naive  = confusion_matrix(y_true, y_pred_naive,  labels=labels)\n",
    "\n",
    "# Plot side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "action_names = [env.env._meta_actions.ACTIONS_ALL[a] for a in action_names]\n",
    "\n",
    "disp1 = ConfusionMatrixDisplay(cm_causal, display_labels=action_names)\n",
    "disp1.plot(ax=ax1, cmap='Blues', xticks_rotation='vertical')\n",
    "ax1.set_title(\"Causal Imitator\")\n",
    "\n",
    "disp2 = ConfusionMatrixDisplay(cm_naive, display_labels=action_names)\n",
    "disp2.plot(ax=ax2, cmap='Greens', xticks_rotation='vertical')\n",
    "ax2.set_title(\"Naive Baseline\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a9bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_records = collect_imitator_trajectories(env, causal_policies, train_eps, num_steps, seed)\n",
    "naive_records = collect_imitator_trajectories(env, naive_policies, train_eps, num_steps, seed)\n",
    "\n",
    "# Prepare label and display names\n",
    "n_actions = env.env.action_space.n\n",
    "labels = list(range(n_actions))\n",
    "action_names = list(env.env.unwrapped.action_type.actions.keys())\n",
    "\n",
    "# Gather true actions once\n",
    "y_true = []\n",
    "for r in records:\n",
    "    y_true.append(r['action'])\n",
    "\n",
    "# Gather predictions for causal and naive\n",
    "y_pred_causal = []\n",
    "y_pred_naive  = []\n",
    "for r in records:\n",
    "    t = r['step']\n",
    "    key = f'X{t}'\n",
    "    # causal\n",
    "    if key in causal_policies:\n",
    "        y_pred_causal.append(causal_policies[key](r['obs']))\n",
    "    else:\n",
    "        y_pred_causal.append(-1)  # or some placeholder\n",
    "    # naive\n",
    "    if key in naive_policies:\n",
    "        y_pred_naive.append(naive_policies[key](r['obs']))\n",
    "    else:\n",
    "        y_pred_naive.append(-1)\n",
    "\n",
    "# Compute confusion matrices (we’ll ignore the placeholder label -1)\n",
    "cm_causal = confusion_matrix(y_true, y_pred_causal, labels=labels)\n",
    "cm_naive  = confusion_matrix(y_true, y_pred_naive,  labels=labels)\n",
    "\n",
    "# Plot side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "action_names = [env.env._meta_actions.ACTIONS_ALL[a] for a in action_names]\n",
    "\n",
    "disp1 = ConfusionMatrixDisplay(cm_causal, display_labels=action_names)\n",
    "disp1.plot(ax=ax1, cmap='Blues', xticks_rotation='vertical')\n",
    "ax1.set_title(\"Causal Imitator\")\n",
    "\n",
    "disp2 = ConfusionMatrixDisplay(cm_naive, display_labels=action_names)\n",
    "disp2.plot(ax=ax2, cmap='Greens', xticks_rotation='vertical')\n",
    "ax2.set_title(\"Naive Baseline\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053cfc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def avg_steps(records):\n",
    "    steps = defaultdict(int)\n",
    "    for r in records:\n",
    "        ep = r['episode']\n",
    "        steps[ep] += 1\n",
    "\n",
    "    if not steps:\n",
    "        return 0.0\n",
    "    \n",
    "    return sum(steps.values()) / len(steps)\n",
    "\n",
    "print(avg_steps(records))\n",
    "print(avg_steps(causal_records))\n",
    "print(avg_steps(naive_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489caaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def filtered(records, state: List[Tuple[str, int]]):\n",
    "    filtered_records = []\n",
    "    for r in records:\n",
    "        for var, val in state:\n",
    "            index = -1 if var in ('X', 'Y') else -2 # X and Y have one less entry in the info\n",
    "            loc = 'obs' if var in env.env.observed_unobserved_vars[0] else 'info'\n",
    "\n",
    "            if -index <= len(r[loc][var]) and r[loc][var][index] == val:\n",
    "                filtered_records.append(r)\n",
    "\n",
    "    return filtered_records\n",
    "\n",
    "# Prepare data for plotting\n",
    "labels = list(range(env.env.action_space.n))\n",
    "action_names = list(env.env.unwrapped.action_type.actions.keys())\n",
    "action_names = [env.env._meta_actions.ACTIONS_ALL[a] for a in action_names]\n",
    "\n",
    "state1 = [('W', 1)]\n",
    "state0 = [('W', 0)]\n",
    "\n",
    "expert_filtered1 = filtered(records, state1)\n",
    "expert_filtered0 = filtered(records, state0)\n",
    "causal_filtered1 = filtered(causal_records, state1)\n",
    "causal_filtered0 = filtered(causal_records, state0)\n",
    "naive_filtered1 = filtered(naive_records, state1)\n",
    "naive_filtered0 = filtered(naive_records, state0)\n",
    "\n",
    "# Count actions for each filtered result\n",
    "expert_counts1 = Counter(r['action'] for r in expert_filtered1)\n",
    "expert_counts0 = Counter(r['action'] for r in expert_filtered0)\n",
    "causal_counts1 = Counter(r['action'] for r in causal_filtered1)\n",
    "causal_counts0 = Counter(r['action'] for r in causal_filtered0)\n",
    "naive_counts1 = Counter(r['action'] for r in naive_filtered1)\n",
    "naive_counts0 = Counter(r['action'] for r in naive_filtered0)\n",
    "\n",
    "# Normalize counts\n",
    "total_expert1 = sum(expert_counts1.values())\n",
    "total_expert0 = sum(expert_counts0.values())\n",
    "total_causal1 = sum(causal_counts1.values())\n",
    "total_causal0 = sum(causal_counts0.values())\n",
    "total_naive1 = sum(naive_counts1.values())\n",
    "total_naive0 = sum(naive_counts0.values())\n",
    "\n",
    "expert_counts1 = {k: v / total_expert1 for k, v in expert_counts1.items()}\n",
    "expert_counts0 = {k: v / total_expert0 for k, v in expert_counts0.items()}\n",
    "causal_counts1 = {k: v / total_causal1 for k, v in causal_counts1.items()}\n",
    "causal_counts0 = {k: v / total_causal0 for k, v in causal_counts0.items()}\n",
    "naive_counts1 = {k: v / total_naive1 for k, v in naive_counts1.items()}\n",
    "naive_counts0 = {k: v / total_naive0 for k, v in naive_counts0.items()}\n",
    "\n",
    "print(f'Expert Filtered ({state1}):', expert_counts1)\n",
    "print(f'Expert Filtered ({state0}):', expert_counts0)\n",
    "print(f'Causal Filtered ({state1}):', causal_counts1)\n",
    "print(f'Causal Filtered ({state0}):', causal_counts0)\n",
    "print(f'Naive Filtered ({state1}):', naive_counts1)\n",
    "print(f'Naive Filtered ({state0}):', naive_counts0)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(3, 2, figsize=(8, 8), sharey=True)\n",
    "\n",
    "# Plot each distribution\n",
    "axes[0, 0].bar(action_names, [expert_counts1.get(a, 0) for a in labels])\n",
    "axes[0, 0].set_title(f'Expert Filtered ({state1}):')\n",
    "axes[0, 1].bar(action_names, [expert_counts0.get(a, 0) for a in labels])\n",
    "axes[0, 1].set_title(f'Expert Filtered ({state0}):')\n",
    "\n",
    "axes[1, 0].bar(action_names, [causal_counts1.get(a, 0) for a in labels])\n",
    "axes[1, 0].set_title(f'Causal Filtered ({state1}):')\n",
    "axes[1, 1].bar(action_names, [causal_counts0.get(a, 0) for a in labels])\n",
    "axes[1, 1].set_title(f'Causal Filtered ({state0}):')\n",
    "\n",
    "axes[2, 0].bar(action_names, [naive_counts1.get(a, 0) for a in labels])\n",
    "axes[2, 0].set_title(f'Naive Filtered ({state1}):')\n",
    "axes[2, 1].bar(action_names, [naive_counts0.get(a, 0) for a in labels])\n",
    "axes[2, 1].set_title(f'Naive Filtered ({state0}):')\n",
    "\n",
    "# Adjust layout\n",
    "for ax in axes.flat:\n",
    "    ax.set_xlabel(\"Actions\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.set_xticks(action_names)\n",
    "    ax.set_xticklabels(action_names, rotation=45, ha=\"right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af9ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_variation(counts1, counts0, labels):\n",
    "    variation = {}\n",
    "    for label in labels:\n",
    "        freq1 = counts1.get(label, 0)\n",
    "        freq0 = counts0.get(label, 0)\n",
    "        variation[label] = abs(freq1 - freq0)\n",
    "    return variation\n",
    "\n",
    "# Compute variations\n",
    "expert_variation = calculate_variation(expert_counts1, expert_counts0, labels)\n",
    "causal_variation = calculate_variation(causal_counts1, causal_counts0, labels)\n",
    "naive_variation = calculate_variation(naive_counts1, naive_counts0, labels)\n",
    "\n",
    "# Print variations\n",
    "print(\"Expert Variation:\", expert_variation)\n",
    "print(\"Causal Variation:\", causal_variation)\n",
    "print(\"Naive Variation:\", naive_variation)\n",
    "\n",
    "# Plot variations\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_labels = [action_names[label] for label in labels]\n",
    "\n",
    "bar_width = 0.25  # width of each bar\n",
    "x_indices = np.arange(len(x_labels))  # positions for the groups\n",
    "\n",
    "plt.bar(x_indices - bar_width, [expert_variation[label] for label in labels], bar_width, label='Expert Variation')\n",
    "plt.bar(x_indices, [causal_variation[label] for label in labels], bar_width, label='Causal Variation')\n",
    "plt.bar(x_indices + bar_width, [naive_variation[label] for label in labels], bar_width, label='Naive Variation')\n",
    "\n",
    "plt.xticks(x_indices, x_labels)\n",
    "\n",
    "plt.xlabel('Actions')\n",
    "plt.ylabel('Variation')\n",
    "plt.title(f'Action Frequency Variation Across States ({state1} vs {state0})')\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cfb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_correct = sum(cm_causal[i, i] for i in range(len(labels)))\n",
    "naive_correct  = sum(cm_naive[i, i] for i in range(len(labels)))\n",
    "\n",
    "print(f\"Causal Correct Predictions: {causal_correct}\")\n",
    "print(f\"Naive Correct Predictions: {naive_correct}\")\n",
    "\n",
    "causal_incorrect = sum(cm_causal[i, j] for i in range(len(labels)) for j in range(len(labels)) if i != j)\n",
    "naive_incorrect  = sum(cm_naive[i, j] for i in range(len(labels)) for j in range(len(labels)) if i != j)\n",
    "\n",
    "print(f\"Causal Incorrect Predictions: {causal_incorrect}\")\n",
    "print(f\"Naive Incorrect Predictions: {naive_incorrect}\")\n",
    "\n",
    "causal_correct / naive_correct, causal_incorrect / naive_incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fef863",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 100\n",
    "testenv = HighwayPCH(num_steps=t, render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, _ = testenv.reset()\n",
    "\n",
    "for step in range(t):\n",
    "    action = causal_policies[f'X{step}'](obs)\n",
    "    # action = naive_policies[f'X{step}'](obs)\n",
    "    obs, reward, terminated, truncated, info = testenv.do(action, show_reward=True)\n",
    "    # action, obs, reward, terminated, truncated, info = testenv.see(show_reward=True)\n",
    "    testenv.render()\n",
    "\n",
    "    if terminated or truncated:\n",
    "        testenv.env._env.close()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
