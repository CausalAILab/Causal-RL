{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9036d927",
   "metadata": {},
   "source": [
    "# Automatic Reward Shaping from Confounded Offline Data\n",
    "This notebook is based on our ICML 25 [paper](https://openreview.net/forum?id=Hu7hUjEMiW&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICML.cc%2F2025%2FConference%2FAuthors%23your-submissions)).\n",
    "Also see the Techical Report version [here](https://causalai.net/r123.pdf).\n",
    "\n",
    "The task is to learn a potential function automatically from offline data to be used in Potential Based Reward Shaping (PBRS). The new reward function after reward shaping is defined to be,\n",
    "$$\n",
    "Y' = Y + \\gamma\\phi(s') - \\phi(s)\n",
    "$$\n",
    "where $Y$ is the original reward signal and $Y'$ is the one after shaping. $\\phi(\\cdot)$ is the potential function we aim to learn automatically from offline datasets.\n",
    "\n",
    "Intuitively, one can use the optimal state values as the potential function. And if the provided offline dataset is generated by a good enough policy, one can directly take the average cumulative return as the state value estimations. However, when the offline dataset is confounded or the data generating policy is sub-optimal, such naive estimations are highly biased and could mislead the policy training. See example 1&2 in the paper for more details.\n",
    "\n",
    "In this work, we use causal bounds to estimate an upper bound on the optimal interventional\n",
    "state values. Then, we take the estimated upper value bound as the potential function to train our online policy learner, Q-UCB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aea67ce",
   "metadata": {},
   "source": [
    "## Environment Definition and Data Generation\n",
    "In this notebook, we will replicate our example results in environment RobotWalk, corresponding to Example 1-3 in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61bf2481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current agent location: 0\n",
      "Current stability status: 1\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import gymnasium as gym\n",
    "from causal_gym.core import Task, PCH\n",
    "\n",
    "GAMMA = 1 # discount\n",
    "ALPHA = .1 # learning rate\n",
    "EPS = .001 # error tolerance\n",
    "LENGTH = 10 # hallway length\n",
    "ACTION_DIM = 2 # action dimention\n",
    "PUT = [.5, .5] # noise distribution\n",
    "\n",
    "# First let's get a brief overview of the environment\n",
    "env_name = 'causal_gym/RobotWalk-v0'\n",
    "# Initialize the environment\n",
    "env: PCH = gym.make(\n",
    "    env_name, \n",
    "    task=Task(learning_regime='cool'),\n",
    "    length=LENGTH,\n",
    "    timelimit=30,\n",
    "    put=PUT\n",
    ")\n",
    "\n",
    "# The goal of the agent is to reach the end of the hallway\n",
    "# before the time is up.\n",
    "state, info = env.reset()\n",
    "print(f\"Current agent location: {state[0]}\")\n",
    "print(f\"Current stability status: {state[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0d918f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optiaml state values\n",
      "[[4.99963 5.5    ]\n",
      " [4.49982 5.     ]\n",
      " [3.99991 4.5    ]\n",
      " [3.49995 4.     ]\n",
      " [2.99998 3.5    ]\n",
      " [2.49999 3.     ]\n",
      " [1.99999 2.5    ]\n",
      " [1.5     2.     ]\n",
      " [1.      1.5    ]\n",
      " [0.      1.     ]\n",
      " [0.      0.     ]]\n",
      "Optimal Q-value for the first two states\n",
      "[[[4.99963 4.99963]\n",
      "  [5.5     4.99927]]\n",
      "\n",
      " [[4.49982 4.49982]\n",
      "  [5.      4.49963]]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "# Calculate state values of perfect interventional policy\n",
    "# By default, the last state is 0 value\n",
    "true_value = np.zeros([LENGTH+1, 2])\n",
    "true_qvalue = np.zeros([LENGTH+1, 2, ACTION_DIM])\n",
    "\n",
    "prev_true_value = np.zeros([LENGTH+1, 2])\n",
    "prev_true_qvalue = np.zeros([LENGTH+1, 2, ACTION_DIM])\n",
    "\n",
    "state, info = env.reset()\n",
    "# Calculated by value iteration\n",
    "while True:\n",
    "    for loc, stable in np.ndindex(LENGTH, 2):\n",
    "        for x in range(ACTION_DIM):\n",
    "            weighted_next_value = 0\n",
    "            for ut, put in zip([0, 1], env.env.stable_u_dist):\n",
    "                env.env.ut = ut\n",
    "                env.env.current_location = loc\n",
    "                env.env.is_stable = stable\n",
    "                sp, reward, _, _, info = env.do(lambda m: x)\n",
    "                weighted_next_value += put * (reward + GAMMA * prev_true_value[sp[0], sp[1]])\n",
    "            true_qvalue[loc, stable, x] = weighted_next_value\n",
    "        true_value[loc, stable] = max(true_qvalue[loc, stable, :])\n",
    "    if np.all(abs(true_qvalue - prev_true_qvalue) < EPS):\n",
    "        break\n",
    "    else:\n",
    "        prev_true_qvalue = copy.copy(true_qvalue)\n",
    "        prev_true_value = copy.copy(true_value)\n",
    "\n",
    "print(\"Optiaml state values\")\n",
    "print(np.round(true_value, decimals=5))\n",
    "print(\"Optimal Q-value for the first two states\")\n",
    "print(np.round(true_qvalue[0:2,], decimals=5))\n",
    "\n",
    "with open('values/OPTQ-robotwalk.json', 'w') as f:\n",
    "    json.dump(np.round(true_qvalue, decimals=5).tolist(), f)\n",
    "with open('values/OPTV-robotwalk.json', 'w') as f:\n",
    "    json.dump(np.round(true_value, decimals=5).tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139ceeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: bad | Avg epi return in dataset: -28.53250773993808\n",
      "Policy: bad | Values estimated via Monte Carlo: \n",
      " [[-15.5        -28.53250774]\n",
      " [-15.         -27.44193548]\n",
      " [-14.5        -26.32236842]\n",
      " [-14.         -25.3125    ]\n",
      " [-13.5        -23.52941176]\n",
      " [-13.         -23.        ]\n",
      " [-12.5        -22.07142857]\n",
      " [-12.         -22.25      ]\n",
      " [-11.5        -22.        ]\n",
      " [  0.           0.        ]]\n",
      "Policy: good | Avg epi return in dataset: 10.0\n",
      "Policy: good | Values estimated via Monte Carlo: \n",
      " [[10. 10.]\n",
      " [ 9.  9.]\n",
      " [ 8.  8.]\n",
      " [ 7.  7.]\n",
      " [ 6.  6.]\n",
      " [ 5.  5.]\n",
      " [ 4.  4.]\n",
      " [ 3.  3.]\n",
      " [ 2.  2.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# Collecting datasets from behavioral policies\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "behavioral_policies = {\n",
    "    'bad': lambda s, ut: 1 - ut,\n",
    "    'good': None # use the default optimal beh. policy\n",
    "}\n",
    "datasets = {\n",
    "    'bad': [],\n",
    "    'good': []\n",
    "}\n",
    "\n",
    "\n",
    "for bpolicy in ['bad', 'good']:\n",
    "    rng = np.random.default_rng(seed=5678)\n",
    "    dataset = datasets[bpolicy]\n",
    "    epi_cnt = 0\n",
    "    total_rewards = 0\n",
    "    state_count = defaultdict(int)\n",
    "    values = defaultdict(float)\n",
    "    state, info = env.reset()\n",
    "    while len(dataset) < 10000:\n",
    "        reward_seq = []\n",
    "        states_seq = []\n",
    "        state, info = env.reset(seed=int(rng.random()*10000))\n",
    "        terminated, truncated = False, False\n",
    "        while not (terminated or truncated):\n",
    "            state_count[state] += 1\n",
    "            states_seq.append(state)\n",
    "            next_state, reward, terminated, truncated, info = env.see(see_policy=behavioral_policies[bpolicy])\n",
    "            action = info['natural_action']\n",
    "            reward_seq.append(reward)\n",
    "            dataset.append([state, action, reward, next_state])\n",
    "            state = next_state\n",
    "            total_rewards += reward\n",
    "        for i, state in enumerate(states_seq):\n",
    "            values[state] += sum(reward_seq[i:])\n",
    "        epi_cnt += 1\n",
    "    output_values = np.zeros([LENGTH, 2])\n",
    "    for state in values.keys():\n",
    "        output_values[tuple(state)] = values[state]/state_count[state]\n",
    "    print(f'Policy: {bpolicy} | Avg epi return in dataset: {total_rewards/epi_cnt}')\n",
    "    print(f'Policy: {bpolicy} | Values estimated via Monte Carlo: \\n {output_values}')\n",
    "    with open(f'values/BEV-{bpolicy}-robotwalk.json', 'w') as f:\n",
    "        json.dump(output_values.tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d6dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Bound\n",
    "def approx_opt_value_upper_bound(\n",
    "    dataset: list, \n",
    "    state_space: tuple,\n",
    "    action_space: int,\n",
    "    horizon: int,\n",
    "    reward_upper_bound: int,\n",
    "    gamma: float = 1.0,\n",
    "    eps: float = .001,\n",
    "):\n",
    "    '''\n",
    "    Calculate the optimal interventional upper value bound\n",
    "    return value upper bounds and state count (support)\n",
    "    '''\n",
    "    offset1 = reward_upper_bound\n",
    "    offset2 = reward_upper_bound\n",
    "\n",
    "    # calculate state-action prospensity score\n",
    "    state_action_count = {stact: 0 for stact in np.ndindex(tuple(state_space) + (action_space,))}\n",
    "    approx_cumu_reward = {stact: 0 for stact in np.ndindex(tuple(state_space) + (action_space,))}\n",
    "    approx_reward_space = {stact: set([]) for stact in np.ndindex(tuple(state_space) + (action_space,))}\n",
    "    approx_cumu_transition = defaultdict(int)\n",
    "    state_count = {st: 0 for st in np.ndindex(tuple(state_space))}\n",
    "    support = set([])\n",
    "    for s,a,r,sp in dataset:\n",
    "        support.add(s)\n",
    "        approx_cumu_reward[tuple(s) + (a,)] += r\n",
    "        approx_reward_space[tuple(s) + (a,)].add(r)\n",
    "        state_action_count[tuple(s) + (a,)] += 1\n",
    "        approx_cumu_transition[tuple(s) + (a,) + tuple(sp)] += 1\n",
    "        state_count[s] += 1\n",
    "\n",
    "    approx_action_prop = {}\n",
    "    for stact in np.ndindex(tuple(state_space) + (action_space,)):\n",
    "        if state_count[stact[:-1]] > 0:\n",
    "            approx_action_prop[stact] = state_action_count[stact]/state_count[stact[:-1]]\n",
    "        else:\n",
    "            # print(stact[:-1])\n",
    "            approx_action_prop[stact] = 1/action_space\n",
    "\n",
    "\n",
    "    value = np.zeros(state_space)\n",
    "    qvalue = np.zeros(tuple(state_space) + (action_space,))\n",
    "    prev_value = np.zeros(state_space)\n",
    "    prev_qvalue = np.zeros(tuple(state_space) + (action_space,))\n",
    "    \n",
    "    # A value iteration approach\n",
    "    # print(approx_reward_space)\n",
    "    while True:\n",
    "        for state in np.ndindex(tuple(state_space)):\n",
    "            if state_count[state] == 0:\n",
    "                continue\n",
    "            for x in range(action_space):\n",
    "                if state_action_count[tuple(state) + (x,)] == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    reward = approx_cumu_reward[tuple(state) + (x,)]/state_action_count[tuple(state) + (x,)]\n",
    "                \n",
    "                next_state_values = 0\n",
    "                next_state_values_non_weighted = 0\n",
    "                next_states_cnt = 0\n",
    "                for sp in np.ndindex(tuple(state_space)):\n",
    "                    if state_count[sp] == 0 or state_action_count[tuple(state) + (x,)] == 0:\n",
    "                        continue\n",
    "                    transition_prob = approx_cumu_transition[tuple(state) + (x,) + tuple(sp)]/state_action_count[tuple(state) + (x,)]\n",
    "                    if transition_prob > 0:\n",
    "                        next_states_cnt += 1\n",
    "                        next_state_values += transition_prob * prev_value[tuple(sp)]\n",
    "                        next_state_values_non_weighted += prev_value[tuple(sp)]\n",
    "                \n",
    "                qvalue[tuple(state) + (x,)] = (approx_action_prop[tuple(state) + (x,)]) * (reward + gamma * next_state_values) + \\\n",
    "                                (1-approx_action_prop[tuple(state) + (x,)]) * (offset1 + gamma * offset2)\n",
    "            value[tuple(state)] = np.max([qvalue[tuple(state) + (i,)] for i in range(action_space) if state_action_count[tuple(state)+(i,)] > 0])\n",
    "        if np.all(abs(value - prev_value) < eps):\n",
    "            break\n",
    "        else:\n",
    "            prev_value = copy.copy(value)\n",
    "            # Update the max value seen so far\n",
    "            offset2 = np.max([prev_value[tuple(s)] for s in support])\n",
    "            offset2 = np.min([offset1*(horizon-1), offset2])\n",
    "\n",
    "\n",
    "    return np.round(value, decimals=3), state_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e2f247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx optimal value upper bound for bad behavioral policy:\n",
      "[[8.034 9.481]\n",
      " [8.018 9.503]\n",
      " [8.02  9.526]\n",
      " [8.01  9.5  ]\n",
      " [8.088 9.676]\n",
      " [8.214 9.458]\n",
      " [8.4   9.286]\n",
      " [8.275 8.833]\n",
      " [8.167 8.167]\n",
      " [0.    0.   ]]\n",
      "Approx optimal value upper bound for good behavioral policy:\n",
      "[[10.051 10.051]\n",
      " [10.077 10.077]\n",
      " [10.01  10.01 ]\n",
      " [ 9.973  9.973]\n",
      " [ 9.9    9.9  ]\n",
      " [ 9.724  9.724]\n",
      " [ 9.426  9.426]\n",
      " [ 8.828  8.828]\n",
      " [ 7.644  7.644]\n",
      " [ 5.256  5.256]]\n",
      "[[8.034 9.481]\n",
      " [8.018 9.503]\n",
      " [8.02  9.526]\n",
      " [8.01  9.5  ]\n",
      " [8.088 9.676]\n",
      " [8.214 9.458]\n",
      " [8.4   9.286]\n",
      " [8.275 8.828]\n",
      " [7.644 7.644]\n",
      " [0.    0.   ]]\n",
      "Final bound:\n",
      "[[8.034 9.481]\n",
      " [8.018 9.503]\n",
      " [8.02  9.526]\n",
      " [8.01  9.5  ]\n",
      " [8.088 9.676]\n",
      " [8.214 9.458]\n",
      " [8.4   9.286]\n",
      " [8.275 8.828]\n",
      " [7.644 7.644]\n",
      " [0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "bounds = []\n",
    "for bpolicy in ['bad', 'good']:\n",
    "    upper_opt_value, state_count = approx_opt_value_upper_bound(datasets[bpolicy], (10, 2), 2, 9, 1, eps=.0001)\n",
    "    print(f\"Approx optimal value upper bound for {bpolicy} behavioral policy:\")\n",
    "    print(np.round(upper_opt_value, decimals=3))\n",
    "    bounds.append(np.round(upper_opt_value, decimals=3))\n",
    "    with open(f'values/BD-{bpolicy}-robotwalk.json', 'w') as f:\n",
    "        json.dump(upper_opt_value.tolist(), f)\n",
    "\n",
    "final_bd = reduce(np.minimum, bounds)\n",
    "with open(f'values/BD-FINAL-robotwalk.json', 'w') as f:\n",
    "    json.dump(final_bd.tolist(), f)\n",
    "print(final_bd)\n",
    "print(f\"Final bound:\")\n",
    "print(final_bd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d06ee5",
   "metadata": {},
   "source": [
    "## Q-UCB and Q-UCB shaping\n",
    "In this section, we will load those trained state values as potentials in our reward shaping function and train an online agent called [Q-UCB]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46c75681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: causal_gym/RobotWalk-v0\n",
      "Optimal Value\n",
      "[[4.99963 4.49982 3.99991 3.49995 2.99998 2.49999 1.99999 1.5     1.\n",
      "  0.      0.     ]\n",
      " [5.5     5.      4.5     4.      3.5     3.      2.5     2.      1.5\n",
      "  1.      0.     ]]\n",
      "=========================================================\n",
      "\n",
      "Experiment: No Shaping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NUM EPISODES:   0%|          | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NUM EPISODES: 100%|██████████| 20000/20000 [00:07<00:00, 2502.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Shaping final 100 epi avg rewards 5.5\n",
      "No Shaping last 10 episodes regrets [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Experiment: Causal Upper Bound (Ours)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NUM EPISODES: 100%|██████████| 20000/20000 [00:09<00:00, 2157.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causal Upper Bound (Ours) final 100 epi avg rewards 5.5\n",
      "Causal Upper Bound (Ours) last 10 episodes regrets [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Experiment: Confounded Values good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NUM EPISODES: 100%|██████████| 20000/20000 [00:09<00:00, 2156.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confounded Values good final 100 epi avg rewards 5.5\n",
      "Confounded Values good last 10 episodes regrets [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Experiment: Confounded Values bad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NUM EPISODES: 100%|██████████| 20000/20000 [00:17<00:00, 1161.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confounded Values bad final 100 epi avg rewards 2.96\n",
      "Confounded Values bad last 10 episodes regrets [50068.5629 50071.063  50073.5631 50076.0632 50078.5633 50081.0634\n",
      " 50083.5635 50086.0636 50088.5637 50091.0638]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from causal_rl.algo.reward_shaping.q_ucb import *\n",
    "env_name = 'causal_gym/RobotWalk-v0'\n",
    "\n",
    "\n",
    "TIME_LIMIT = 10\n",
    "PRECISION = 2\n",
    "env: PCH = gym.make(\n",
    "    env_name, \n",
    "    task=Task(learning_regime='cool'),\n",
    "    length=LENGTH,\n",
    "    timelimit=30,\n",
    "    put=PUT\n",
    ")\n",
    "OPT_VALUE = np.array(json.load(open(f'values/OPTV-robotwalk.json', 'r')))\n",
    "OPT_QVALUE = np.array(json.load(open(f'values/OPTQ-robotwalk.json', 'r')))\n",
    "bevalues = [json.load(open(f'values/BEV-{n}-robotwalk.json', 'r')) for n in ['good', 'bad']]\n",
    "bounds = [json.load(open(f'values/BD-{n}-robotwalk.json', 'r')) for n in ['good', 'bad']]\n",
    "PRESET_BOUNDS = [\n",
    "    np.array(OPT_VALUE) + 1.0,    # no shaping placeholder\n",
    "    np.array(json.load(open(f'values/BD-FINAL-robotwalk.json', 'r'))), # our bound\n",
    "    np.array(bevalues[0]), # bad confouned value from perfect bpolicy\n",
    "    np.array(bevalues[1]), # bad confounded value from bad bpolicy\n",
    "]\n",
    "NAMES = ['No Shaping', 'Causal Upper Bound (Ours)', 'Confounded Values good', 'Confounded Values bad']\n",
    "COLORS = ['dodgerblue', 'mediumseagreen', 'orange', 'mediumturquoise','wheat']\n",
    "\n",
    "print(f'Env: {env_name}')\n",
    "print('Optimal Value')\n",
    "print(np.transpose(OPT_VALUE))\n",
    "print(\"=========================================================\\n\")\n",
    "\n",
    "for i, bound in enumerate(PRESET_BOUNDS):\n",
    "    #  0 - no shaping, 1 - shaping w/ given potentials\n",
    "    mode = 0 if i == 0 else 1\n",
    "    print(f'Experiment: {NAMES[i]}')\n",
    "    q_table, visit_cnt, total_steps, epi_rewards, epi_regrets, trajs = QUCB_HM(\n",
    "        env=env, \n",
    "        state_space=(10, 2), \n",
    "        action_dim=2,\n",
    "        mode=mode, \n",
    "        upper_value=bound, \n",
    "        max_steps=TIME_LIMIT, \n",
    "        max_episodes=MAX_EPISODES[env_name], \n",
    "        seed=5678, \n",
    "        precision=PRECISION,\n",
    "        opt_value=OPT_VALUE,\n",
    "        opt_qvalue=OPT_QVALUE\n",
    "    )\n",
    "    print(f'{NAMES[i]} final 100 epi avg rewards {np.round(sum(epi_rewards[-100:])/len(epi_rewards[-100:]), decimals=3)}')\n",
    "    print(f'{NAMES[i]} last 10 episodes regrets {np.round(epi_regrets[-10:], decimals=4)}')\n",
    "    with open(f'values/UCBQ-robotwalk-{NAMES[i]}.json', 'w') as f:\n",
    "        json.dump(q_table.tolist(), f)\n",
    "    with open(f'regrets/REG-robotwalk-{NAMES[i]}.json', 'w') as f:\n",
    "        json.dump(epi_regrets, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdf114b",
   "metadata": {},
   "source": [
    "## Experiment Results\n",
    "In this section, we will visualize our experiment results and also render a video of our trained agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ce488fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "causal_gym/RobotWalk-v0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADUCAYAAACMCNgJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABExElEQVR4nO3dd1iTV/sH8G8SSMKMuBAVAUURByC4QAVUrNZV6q5afbXOqpXXDrWttbbW/atW66yvYuvA2qqtu1ZFq9YBOHALggLKUiDMzPP7I/JIJCAJIaz7c125JA/PuAnx5uQ859yHxxhjIIQQUu3xKzsAQgghxkEJnRBCaghK6IQQUkNQQieEkBqCEjohhNQQlNAJIaSGoIROCCE1BCV0QgipIaptQmeMQSqVguZFEUKIRrVN6NnZ2ZBIJMjOzq7sUAghpEqotgmdEEKINkrohBBSQ5hVdgCEEFLTZeTKEfUkA5l5ctSxFMK7mR3srIRGvw4ldEIIqUDXn2TgzxtJKDp+42JMGgZ5NoFXMzujXosSOiGkRjJVq5gxBrlKDblS85C9/FeuUiMjV4YTt5Lx+lg8NQMO3UiCUz0ro8ZECZ0QUuOU1ipu20TCJd/CxCtTql57XuT7SpVWwuaStkrzPYXKsKHTagZEPclAb3d7I/3Ueib0rKwsfPHFF4iPj8fhw4dx584d3LhxA++9957RAiKEVF8V1SpWM6ZJpAoVCl7+K1NqErFMoea+LlCokV0gx91nxYczqxnwx/Uk/HE9qdzxGEtmntyo59MroU+dOhXt2rVDeHg4AMDFxQWjR4+mhE4IKbFV3K+dA1o1stFKvDKFGgVcMn6ZnEtI0jKFpjVcVQj4PAjN+BAK+BCa8SHivhZothc+BHw8eZ6LR+m5JZ6rjqVxu4D0SugPHjxAWFgYfv/9dwCAhYUFzdQkpJJVZF8xYwxKFUOBUoV8uQoFChXyFUX+lauQr1BDmi/HvWTdreKj0c9wNPqZUeIxBiuhAE3sLLUSb+HXIjOB1nPthK15CPhlH+2dkSvHj6cfQK0jTfJ5gHdl3hQVCrXfJPn5+ZTQCalEZRlBwRiDQqV+mYDVpSbnV9vU3PdUurKRCQjN+BCb8SEyF0D0MtmKzF/+q7WdD3GRfa4lZCDqcUaJ5+3gVNeo/dalsbMSYpBnExy6kaSV1Pk8YLBXE6PfpNUroffs2RPfffcdCgoK8Pfff2P16tUYMmSIUQMihJRMpVYjV6ZCnlyJFGkB/ryepHMExR/Xk3D2firkKjUKFGqoK7nhZSs2Q/OG1lwyFpeYpPkQv+y64PF4Bl3LSmSG608yTNYqfhOvZnZwqmdlkhE3PKZHE1upVGLlypU4ePAgGGMIDg7G3LlzIRAIjB7Ym0ilUkgkEmRlZcHW1tbk1ye1mzG6OQqHu+XJVMiVK5EnVyFPptR8/TJp58lffk+m+VqmNE1fslDAh1gogIW5AGJzTQLWfK15WAgFWttuJGQgspRWcfeWDUzWKgY0n1xKahV7Opo2oZuSXgldH+fOncPKlSsRGRmJZ8+e4cCBAwgODua+zxjDwoUL8dNPPyEzMxPdunXDxo0b0bJlyzKdnxI6qSy6ujn4PGCgZxO0srd5lYhfJuE8uZJrVee9TNaFCbwiuzP4PMBGbK6ViMVCPvfcooTkLDYXQMDXr3X8pr7imb1aVUiL9E0xmaJVXJWUqctl7dq1pX7/o48+KrYtNzcXnp6emDhxos5umRUrVmDt2rXYsWMHXFxcsGDBAvTt2xd37tyBWCwuY/iEVDyFUg1pgQLZBUokZ+Xjr9u6J4r8WYHD4cTmAlgJBbAUmsFSpPk3LbsAiRn5JR7j52q6VrGp+4rLGpMpPxVUBWVK6NeuXSvxeyX1c7399tt4++23dX6PMYY1a9bgyy+/xDvvvAMA+Pnnn2Fvb4+DBw9i1KhRZQmL1DLGbnGpGUOuTAlpviZZZxcoIH35b/bLBC7NVxi9m4PPgyYxCwWwEplxX1uKzLSSttXL7RZCM50tZlOPoHgTU/YVE93KlNC3b99u1IvGxcUhOTkZQUFB3DaJRIIuXbrg33//1ZnQZTIZZDIZ91wqlRo1JlK16VMPgzEGmVKtSdD5rxL0q2St+TenQFmspV1e1iIztGhgzbWiX0/aViIziMpxw68oahWT1+k99f/p06e4desWCgoKuG2DBw/W6xzJyckAAHt77V+8vb09973XLV26FIsWLdIzWlITZOTKiyVz4FU3x5MXeVCqXnWLZBcoDJ6OXZQZnwcbsTlsLcxgIzaHjdgMyVkFiCtloohXMzuTJjRqFZOi9Ero27ZtwzfffIMXL16gZcuWuHHjBrp27ap3QjfE/PnzMWfOHO65VCqFo6NjhV+XmB5jDFn5CrzIleN5jgzXEzKLJXNuXwDXnpQ8uqIk1iIz2IjNYGthDmuRdtK2FZvDRmwOsXnxlnRV6+YAqFVMXtEroa9evRrXrl1Dr169EBkZiXPnziE0NFTvizZq1AgAkJKSAgcHB257SkoKvLy8dB4jEokgEon0vhapmtjL/uvnL5P281w5XuTI8TxXhoxcOZQGjv4QmfG1ErP1y6SttU1kBr6eozgKVcVuDkIK6T1T1M7ODkqlEgDg7++PkJAQvS/q4uKCRo0a4dSpU1wCl0qluHz5MqZPn673+UjFKe+NyHy5UitZP8+R40WuJoHLjXSzsX0TCfzdGsJWbAahWcXPiaBuDlJV6ZXQRSIRGGNo1aoV1qxZAycnJ+Tk5OjcNycnBzExMdzzuLg4XL9+HXXr1kWzZs0QEhKCxYsXo2XLltywxcaNG2uNVSeVq6w3IuVK1cvuEU3S5pJ3rhz5cpVe1xTwebCzFKKetRB1rUSoZyWE0IyHg9eSSuzm6Nna3uTJlLo5SFWkV0JfvHgxpFIpVqxYgWnTpiEzMxMbNmzQuW9ERAR69uzJPS/s/x4/fjxCQ0Px2WefITc3F1OmTEFmZia6d++O48eP0xj0KuJNNyJjUrORI1PiRa4c2QVKvc7NA1DH0hz1rEWoayV89a+VCBJLc/B1jABRqUHdHIS8QYXNFK1oNFO0Yh2/9QyXHz0v1zlsxWaoa61pZde1EqGetSZp21mZ61WxrlBtnPlHiD70aqFPmjQJy5cvR7169QAA6enp+OKLL7B58+YKCY6YTq5MifjnuYhPz8Xj57lIy5a9+SAAlkIB6hUm7Zf/apK2EEIz/ZN2aaibg5DS6ZXQIyMjuWQOAPXr18fVq1eNHhSpeIYm8EKejnXQr50DxOamL8xGCNFNr4ReOLqlEGMMcrlxl1AiFSOnQInHz3O5JJ6eU3IC5wFoYCNCWrZM50xKPg8IaNWQkjkhVYxeCb1r166YOXMmPv30UzDGsGrVKnTt2rWiYiPlkFOgQPzzPK4FXmoC5wGNJRZwqm8F53pWaFbXEiJzQaklSKnvmpCqR6+bolKpFCEhITh8+DAAzZT/1atXw8bGpsICLC0Wuin6it4JvI4FnOtZwbm+FRzrWkJUwvhtuhFJSPVBo1yqoLIk0ewChaYLJV3TjfI8p+SuLx4PaFLHAk5lSOCEkOpLry6XzZs3Y9SoUZBIJJg5cyYuXbqE77//Hv7+/hUVX61T0mSePm0awUpkhvjnmhZ4aQmc/7IFTgmckNpFrxa6h4cHbt68iQsXLuDzzz/H559/jgULFuDKlSsVGaNONbGFnpErx7rTD0osRFWSwgTu/LIP3LGupUmmwBNCqha9WuhmZprdT58+jXHjxqFv376YP39+hQRWG0U9yShTMufzgCZ1LLmbmJoEbtwx34SQ6kevhM7n87F3717s3bsXR44cAQAatmhEmXmlv5YNrEXo286BEjghRCe9ssL69euxZ88eTJ48GU5OTnjw4AF69epVUbHVOnUsSx894uZgixYNrSmZE0J0MniUS0ZGBuzsTF/Mv1BN7UOvaiunE0KqD4Ober179zZmHASaWiVdm9cvtp0m8xBCykLvNUULVdPh61WeQvVq0QfHupZwqmdFk3kIIWVicAvd1dW1XBdWqVRYsGABXFxcYGFhgRYtWuDbb7+t1X8oGGO4lywFoFnoYUxXJ/R2N/3iDYSQ6sngFvq+ffvKdeHly5dj48aN2LFjB9q2bYuIiAhMmDABEokEH330UbnOXV09zcznFoto3sCaJgMRQvSiV0KfMGFCsVXQ69SpA19fXwwfPlyvC1+8eBHvvPMOBgwYAABwdnbGnj17KmWSUlVxLzmb+7p1I9PXxyGEVG96dbmIRCJERESgRYsWcHV1RVRUFF68eIG1a9fi888/1+vCfn5+OHXqFB48eAAAuHHjBs6fP4+3335br/PUJPeeSbmv3RrVjJE7hBDT0auFfvfuXVy8eBHW1tYAgI8++gj9+/fHiRMn0LFjRyxZsqTM55o3bx6kUilat24NgUAAlUqF7777DmPGjNG5v0wmg0z2qoKgVCrVuV91lZ4j4yokNqtrCSuRwb1hhJBaSq8WelpaGpfMAcDa2hrp6emwtLSESCTS68K//vordu3ahd27dyMqKgo7duzAqlWrsGPHDp37L126FBKJhHs4Ojrqdb2qjlrnhJDy0mti0ahRo2BpaYkJEyYAAHbs2IHs7Gz8/PPP6NatGyIiIsp8YUdHR8ybNw8zZszgti1evBg7d+7EvXv3iu2vq4Xu6OhYYyYW/e+fWCRm5AMAZvVuibpW+v2BJIQQvVroW7duRb169RASEoKQkBDY2dlh69atEAgEOHbsmF4XzsvLA/+1ld8FAgHUarXO/UUiEWxtbbUeNUV2gYJL5g1tRJTMCSEG0auj1traGitXrtT5vQYNGuh14UGDBuG7775Ds2bN0LZtW1y7dg3ff/89Jk6cqNd5aoL7RUe3ONScP1SEENPSK6FnZ2dj3rx5OHnyJACgb9++WLJkiUFL0K1btw4LFizAhx9+iNTUVDRu3BhTp07FV199pfe5qrui/eeU0Ks/xphW9yAh+jA3N4dAYNgcFL360N9//31YWlpi+vTp4PF42Lx5M7Kzs/HLL78YdPHyqCnFuQoUKqw8fg9qxiCxMMfsoFbFxvqT6iUpKanGjcIipsPj8dC0aVOtAShlpVcL/ebNm7hx4wb3fMOGDfD09NT7ouSVhynZUL/8m9rawZaSeTWnVCohlUpRr169at3QIJWDMYa0tDQkJiaiZcuWerfU9UroKpUK2dnZXBdLTk4OVCqVXhck2gprtwA0O7QmUCo1pRtsbGwgFosrORpSHTVo0ADx8fFQKBR6J3S9RrmMHz8eXbt2xTfffINvvvkGXbt25YYwEv0pVWrEpOQAACyEAjSra1XJERFjedMnrSx5Ac6nPMGRhIc4n/IEWfICva8RHx8PHo/Hlcs4fPgwvv766zcep1Qq8f7778Pf3x9+fn743//+BwDo2LGj3jEUNXXq1HIdTzTK8yldrxb6p59+inbt2uHUqVMAgFWrVqFfv34GX7y2e5SeC/nLcrlu9jbg86m7pTa4nZGGv5JiUfTmVUTaM/Rp0hxt7fQbLdamTRusWLECv/32W5mPOXHiBBo1asTd+8rIyNDrmiXZvHmzUc5DDKf3/PK33367VtdbMSYa3VL7ZMkLiiVzAFCD4WTSIzS1soFEWPauGnd3dyiVSq4mUqGwsDCsXr0aPB4PixYtQt++fbnvWVhY4Pr163j8+DGcnJy4lcfUajVmzpyJq1evYsiQIZg7dy5OnjyJxYsXIy8vD0OHDsW8efMQGhqKgwcPQi6XIzs7G2FhYWjSpAk6duyIiIgI/Oc//4FYLEZsbCysrKxw4MABqFQqjBo1CpmZmXBzc0Nubi5CQ0MNfRlJCcqU0N99991SPwbs37/faAHVFmrG8OBl/7m5gIfmDfS/o02qtl0x0chVKrS2yVTKYsm8kBoMPz+8CZGg+H9LKzNzjHFtr/O4Tz75BCtXrsQ777wDQHOva+nSpbh8+TLkcjl69eqlldB79eqFO3fuYOTIkcjNzcWWLVvg6+uLzMxMfPrpp2jatCk8PT0xd+5cdOvWDWfPnoVarUaXLl0we/ZsAIClpSUOHjyI48ePY/ny5Vi7dq1WTH5+fti0aRNGjhyJ6OhoPHjwAK1atcKSJUuwZcsWXLx4sawvI9FDmRJ6cHBwBYdR+yS+yEOuXHND2bWhDcwFtPBzTZOrVCBHKdfrGAVTQ6HnMd27d8dXX32FZ8+eAdDUXGrWrBnEYjHEYjHMzc2hVCphZvbqv/vMmTMxc+ZM3Lt3D5MmTcL58+dhZ2cHJycnAOBu6EZGRmLRokVQKBSIj49HamoqAMDHxwcA0KlTJ/zwww/FYurQoQMATYmPjIwMxMTEcMf4+PhQQq8gZUro48ePr+g4ap2io1vcaHRLjWRlZl5sm0ylhILpLm8BAOY8fokt9NKEhITgiy++wNChQ9GgQQM8fvwYBQUFkMvlkMvlWsn82bNnsLW1hZWVFerXf7WGra5P4StWrMCmTZvQvHlzeHt7cyuKXbt2DQAQERGhc/WyoudijMHV1RXXrl3D0KFDuWOJ8VGN1krAGOP6z3k8oJU9JfSaSFcXSZa8ANsf3IBaR8cLHzyMa+mhVx96oUGDBmHevHkANDWR5s2bB39/f/D5fCxevFhr34SEBPz3v/+FmZkZlEolvvvuuxLPO3ToULz77rto37691oxwuVyOfv36IScnB3v27HljfMHBwQgLC0Pv3r3RvHlzmJuX/geKGEavmaJVSXWeKZoiLcCm8BgAgEt9K4zzc6nkiIixFBQUIC4uDi4uLiWOQ7+dkYaTSY+0kjofPLzVpDna6DnKpTKEhoYiJycHM2fO1Os4hUIBc3NzbNmyBRkZGZg7d24FRVi9leU9VBJqoVcCGt1Su7W1a4CmVjaIzkhFllwGiVCE9nYNDWqZVyfvvPMOcnJyIBKJsHfv3soOp0aihF4JqP+cSIRidLdvVtlhGOQ///mPQccdPXrUuIGQYso1tMLd3R0eHh7YvXu3seKp8TLz5EjO0swKbFzHAhILYSVHRAipKcrVQj916hQSExNx7tw5Y8VT41HrnBTKlmr+sNvY1uyuFmI6Bid0xhhsbGzQuXNndO7c2Zgx1Wj3n71azMKd+s9rtaTELPAAuLWhhE6MQ68ulw8++ACZmZmQy+Xw8vKCvb09NmzYYPDFk5KSMHbsWNSrVw8WFhZo3769XuuSVjd5MiUeP88FANS1EqK+NS01V1splWqkJmcjJTkHSmXJ49IJ0YdeCT0yMhJ16tTB8ePH0aFDByQnJ2PTpk0GXTgjIwPdunWDubk5jh07hjt37uD//u//uLoSNdGDlGxuoBrVPq/dUpKzoVIxqFSaxG6oixcvIjAwEAEBAejVq1eFNIhCQ0Px448/lrrt66+/xuHDh41+7aJsbGwQGBiIzp074/vvvzf6+UuqVrlhwwauIGF0dDR69+6NgIAADBw4EAkJCQZfr3A+gDHp1eVSOGT9n3/+wcCBA2Fra2vwUknLly+Ho6Mjtm/fzm1zcanZ47G1a59Td0tt9jQxS+vrxk0lep/jxYsXmD59Oo4fPw4HBwdkZWUhNjbWmGFWKrVarbWQvJubG8LDw8EYg5eXF2bPnm1w/ikrxhj+/PNPHD9+HAqFAmPHjsX+/fvRokULXLhwAWPHjsXZs2ffeJ7XfxZAUxYhOTkZmZmZqFOnjlHi1auF3qhRI0yfPh379u1DUFAQFAqFwQtc/Pnnn+jYsSOGDx+Ohg0bokOHDvjpp59K3F8mk0EqlWo9qhO5Uo3YVE3tc2uRGZraWVRyRMRUnj2V4uypGJw5+ZB75GS/WnM0O1um9b2zp2Lw7Omb399HjhxBcHAwHBwcAAASiQTe3t6Ijo5GQEAAfH19uck/4eHh+OSTTwAAt27dwn/+8x8oFAoMGjQIgYGBCAwMREFBAU6ePImAgAB06tQJy5Yt0/tnDQ8Px1tvvYVBgwahU6dOiI6OBgB4e3tjypQp8PX15RaaT09PR3BwMHr16oUxY8ZApVIhPDwcgwYNwrvvvltiNcbCUgZ8Ph8qlQpjx45FQEAABgwYgIyMDMTHx2PYsGEANIvwBAYGAgACAwMxZ84c+Pv7c69LVlYW+vXrh379+mHnzp3FrhUdHY3mzZsDAC5dugQvLy+0aNECANCtWzeo1WokJCRofUL58ccfERoaivj4ePj7+2PkyJFYvnw5FixYAD8/P/Ts2ROXLl0CAPTo0QMnTpzQ+3UuiV4JfdeuXXBzc0NYWBjq1KmDpKQkzJkzx6ALP3r0CBs3bkTLli1x4sQJTJ8+HR999BF27Nihc/+lS5dCIpFwD0dHR4OuW1li03KgVGs+4bg1sqHullog4tITXDwXh7iY5xAI+CjLr5zHAwQCPuJinuPiuTjuEXHpSbF9nz59isaNGxfb7urqivDwcPz7779ISEjAw4cPdV7ryZMnsLS0RHh4OM6cOQOxWMxVV7x8+TJ+//135Ofn6/1z5+Xl4c8//8TPP/+ML774AoCmi/Xjjz/GhQsXcOjQIaSmpmLZsmX46KOPcPr0aXh4eODAgQMANEl2//79mDhxotZ579+/j8DAQLi7uyMoKAg8Hg8HDhxA06ZNcfbsWYwaNQrr1q0rNbbg4GCcO3cOkZGRyMrKwk8//YQhQ4bg+PHjcHZ2Lrb/vXv3uISu6/Vu2rQpnj59WuL1kpKS8Msvv2D+/Pn466+/cO7cOZw5c4YbSNK8eXPcuXOn9BdUD3ol9E2bNiEkJARdu3YFADg7OyMxMdGgC6vVanh7e2PJkiXo0KEDpkyZgsmTJ5fYJz9//nxkZWVxj/L0XVUGmh1a+8jlKshkSshkSigUKpSlyAZjgELx6rjCh1xe/JNw48aNkZSUVGx7XFwc+vfvj4CAAERFReHp06fFimUBQIsWLeDn54exY8fiyy+/hEqlQmRkJIKCgtCzZ0+t6oqvE4vFkMlefcooKCiAhYXmU2eHDh3A4/Hg7u7OVYC0traGm5sb+Hw+PD09ERcXhzt37mDhwoUIDAzE/v37kZycDECzcpKuBk9hl0tsbCxiY2Nx6dIlxMTEoFOnTgA0lR8fPnyo82ctVFgFskmTJsjMzNSqAll4npI4ODgUS96JiYlo3Lhxidf09PSEUKiZa7Jo0SJMnDgRU6dOLfF1LS+9ErquuueG1kJ3cHBAmzZttLa5u7vjyZPiLREAEIlEsLW11XpUFyo1w4MUzY0vkRkfLvVpqbnaQCgUQCQy03oIhSX3+erav7TjBgwYgD/++INLmlKpFFFRUdi4cSM+/vhjnD17Fh06dABjDHZ2dlzjq3Chd5lMhlmzZmHnzp1IS0vDhQsXuOqKZ86cQZMmTYolxELt27fHhQsXAGgaZ1evXoW7uzsA4Pr162CM4f79+1x3UE5ODh4+fAjGGG7evAlnZ2e0bt0aS5YsQXh4OC5fvswtYfd6X/PreDweJBIJUlNT4erqyi3Bd/XqVbRs2ZLrPSj6sxY9tlDRKpAAdN5QdnNzw6NHjwAAXbt2RVRUFHefovDnd3R01Pn6vv6zBAQE4Oeff0ZAQAC2bNkCQNNTUfi6GUOZboqeOHECx48fL9bFkpWVVcpRpevWrRvu37+vte3BgwdcPeaa5PHzXBQoNC2slvY2ELzhDUtqho5di0/tT0/LQfT1Zzr3d2vTEPX1WOikbt262LhxI9577z0wxiAQCLBy5UoMGjQIs2fPRuvWraFWa4ZEtm/fHnl5eejTpw/atWsHAHj8+DE++OADCAQCWFlZwdvbu8Tqiq9r27YtfHx80L17dzDGMHr0aDRu3BgPHjyARCLBoEGDkJKSwq1XamdnhzVr1iAyMhLvvvsu7O3t8cUXX2Dy5MlYuHAhAE2p3tIUdrkolUo0adIE/fr1A5/Px/79++Hv7w9ra2vs3LkTEokEHTp0QI8ePRAQEFDqOSdNmoQRI0bg119/hYODQ7GBGR4eHlwCFwqF2LlzJyZPngyVSgUrKyuu333YsGEYPHgwjh49WuLrFhwcDJlMBqVSiY0bNwLQDDApz9Dv15Wp2uLZs2cRHh6OTZs2Ydq0adx2W1tbvPvuuzr7nt7k6tWr8PPzw6JFizBixAhcuXIFkydPxpYtWzBmzJg3Hl+dqi0ejX6Kq3EvAADDfBzRton+IxpI9fCmSnlxsc8R/+gF+HweWrk3BAA8uJsKtZrBuXlduLSoZ+qQjSo8PByHDx/GqlWrtLYXLk9XHa1fvx6tW7dG7969jXrehIQE/N///R/WrFmjtb3Cqy0GBAQgICAAwcHB8PT01OsCJenUqRMOHDiA+fPn45tvvoGLiwvWrFlTpmRenTDGcP9l/7mAz4NrQ1pqrjbLlspgZSVEW49GsHo5sczWVoRbN5ORLZW94WhSGWbMmFEh53V0dCyWzMtLr3HodevWxcCBA5GYmIjr16/j+vXrOHPmjMGD4wcOHIiBAwcadGx18SyrANICJQCgeX0riMwrdtwsqdqsrDXJXFBkyUEraxE6dnFE/KMXlRiZcRQOgXxddW2dVzd6deZOnToVo0aN4m6UtGvXDtu2bauQwGqKoqNb3Gh0S63XomV9rWReSCDgo0XL+jqOIKTs9EroqampGDt2LHfn1szMTGutQlKcVnVFe0rohJCKo1dCNzMz0xrGlJGRUeKwJgI8z5Eh7eWMQMe6lrAW0x8/QkjF0SuhDx8+HFOnToVUKsXWrVvRp08fTJo0qaJiq/a0JhNR7RZShEKhQHp6Op49e4b09HQoFAqDzlPe4lzbt29Hly5d8Msvvxh0/ZJ07NixTPu9XhCLMYb27dtDLpdz27755hud8RWd4l/VFE7/NzW9mowff/wx9uzZg6ysLPz111+YM2cORo8eXVGxVXvaxbhoMQuikZWVhZSUFK1tL168gL29PSSSsg9pNUZxrrCwMBw/frzKVDnl8Xjo3bs3/v77b/Tv3x8AcOjQIa7aISldmVvoKpUKQUFBeO+997B37178+uuvlMxLkV2gQGKGpg5GQxsR6lLtcwJNy/z1ZF4oJSVFr5Z6ScW5pFIpBg8ejICAAIwaNQpyuRzh4eHo168f3n33XXh6euLWrVvYvXs3Ll++jMGDB+PKlSsICwtDly5d0LVrV65gVGBgIHJyNEXlhg0bhvj4eISGhmLo0KFcAa7CmarLli2Dr68vpkyZwk1oevToEfr27YvAwEBuNNybCmINHz4cv/32GwDNZEMHBwfk5+ejZ8+e6NGjB4YNG1asKKCuOAsKCjB27Fj06tULgwcPhlQqRWxsLFcgq3BmalEffvgh/P398emnn3Kjdc6cOYOuXbuia9eu+PnnnwFoinZ1794d3bp1w9KlSwFoxpX36NEDb7/9Nv7+++8y/x6NqcwJXSAQIC8vj/tFkdLdL1Ljmka31E6PHz/Go0ePtB7x8fGlHhMfH1/smEePHuHx48fF9i2pONeWLVvQv39/nD17Fm3btkVYWBgAzR+TAwcOYNmyZdi2bRtGjx4NLy8vHDt2DD4+Pli6dCnOnj2Lv/76iyuqVRKJRIJDhw5h4sSJ2LdvH1JSUnDs2DFcvHgR//3vf5GRkQEAmDdvHjZs2IDw8HAUFBQgIiLijQWx/Pz8EBERAaVSiX379mH48OGws7PDyZMn8c8//6BJkyY4ffp0qfEBwNatW9GrVy+cPn0aY8aMwZYtWxAeHo6xY8fizJkz3GzNQhEREcjMzMS5c+fQp08fbvv8+fNx+PBh/PPPP1i7di3y8/Px+eef46effsL58+dx5swZxMfHcxUVjx07pveEIGPRqw+9U6dOGDhwIHbv3o0///yTe5Di7hfpbnGn/vNaSaVSQalUaj3eNIiAMVbsGKVSqbNMdUnFuXQVrAIALy8vAJoJLYUJt1BaWhqaNWsGsVgMW1tbmJubQ6lUllh0qrDIVeG54uLi4OHhwRXlsrbWTKC7d+8ePvjgAwQGBuLKlStITEx8Y0EsHo+Hnj174vTp0zh06BAGDx6M58+fY9iwYQgICMDRo0eLFcnSFeedO3ewceNGBAYGYu3atUhPT8eIESMQFxeHMWPGFPt0UDSuwn8Bze+xfv36MDc3h6urK54+fYrk5GS4u7uDx+PB29sbsbGxehX6qih69aHfvHkTALTqlvN4PAwePNi4UVVzBQoVHqVplpqTWJijkYTWjKyNdC2+oFKpSk3qPB5P53G6tg0YMAA9e/bE9OnT4eDgAKlUipiYGK5glY+PD1ewqvDchV6PoUGDBnj8+DEKCgogl8u5muOFRadcXV1x+/ZtrTiLnsvZ2RnR0dFgjOHBgwdc94ebmxtWrVoFJycnMMagUqkQExODa9euwcfHBxERERCJindHDh8+HAsXLkSDBg0gkUiwdetWDBw4EJMmTcKsWbOKxa8rztatW8PX1xfvv/8+AM0nFKVSydVjb9u2rdYwbFdXV66meWHBLkBTYCs9PR0SiQQPHz5E48aNYW9vj7t376J169aIiorCtGnTuEJfQUFBiIiIQN++fYv9XBVNr4R+5syZioqjRolJzYaaFdY+p6XmaitdheYUCgXi4uJKPMbZ2Rnm5uZlOn9JxbkmT56MMWPGICwsDPb29pg7dy4uXrxY6rkEAgHmzZsHf39/8Pl8LF68GICmT3n48OHw8PCAvb19icc3atQIb731Fnx9feHj48PdZF2+fDmmTZuGgoICCAQCbNu27Y0FsQBN8b579+5x/dO9e/fG+++/j0OHDnFleovSFeeUKVMwZcoUblW0jz/+GDk5OdzSeX379tWqhtixY0fY2trC398fHTp04H4PS5YswYABA8Dj8TBz5kxYWFjgu+++w6RJk8AYw4ABA+Ds7IzPPvsMo0ePxqpVqyqtvlSZinMVOnfuXLFtderUQatWrUzeZ1SVi3P9FvEEt1+uODPOzxku9al+S21RlsJKuka5AJqkWNXey7WNQqGAubk5/vrrLxw4cKBYP7spVHhxrkIfffQRtyQTj8dDbGws3NzckJWVhZ07d6Jnz556XbwmUqrUeJii+bhpYS6AU12qfU60SSQSWFpaIisri0sgEomkzC1zUnGmTp2K2NhYqNXqEldPq8r0Sug+Pj5Ys2YNN5zn7Nmz2LFjBz788ENMmzaNCvAAiEvPhVylGQnUqpEN+HzqbiHFmZubo359qt1S1VT32lR6jXKJiIjQqqQWEBCAyMhIdOzY0eCZbjWN9mQi+vhMCDEdvRI6n8/X6kc/d+4cd1OhvDf+li1bBh6Ph5CQkHKdpzKpi9Q+NxPw0EKP1WcIIaS89OpyWb9+PUaNGsX19SkUCoSFhSEnJ8fgmuiAZvWizZs3w8PDw+BzVAWJL/KQ+3IxX9cG1jA3o6XmCCGmo1fG8fPzQ2xsLA4ePIiDBw8iJiYGfn5+sLa2xvjx4w0KICcnB2PGjMFPP/1UZepJGOpekdmhrWl2KClFRq4cp+6m4PfIBJy6m4KMXPmbD9KBinMZrziXoef75JNPEB4ebrQ4ykPveq5//vkn7t+/j88//xxPnz7F8+fP0b59e4MDmDFjBgYMGICgoCBu7Gt1xBjjqivyeJrFoAnR5fqTDPx5IwlFBwxfjEnDIM8m8GpW9kYNFecir9Orhf7VV19h69atXFlIHo+ns8BNWYWFhSEqKoqbPFAamUwGqVSq9ahK0rJlyMjTtCqc6lnBUki1z0lxGbnyYskcANQMOHQjSa+WOhXnesVYxbmSkpIwZMgQeHt7c/ViVq5cicDAQHh7e+PkyZMAgBs3bnClUApn0FcFemWdP/74A1FRUdzHKQcHB+5F1FdCQgJmz56NkydPlmnw/NKlS7Fo0SKDrmUKd6n2OXnNlrMxyJEptbbJFKpiybyQmgGbwh/qXHfWWmSGKQGuWtveVJxr2rRp+PbbbxEWFoZmzZpBoVDg+PHjOHbsGLZt24bvv/8eW7ZsweHDh2FhYYHJkyfj8uXLkMvl6NWrV6lT1yUSCbZt24aNGzdi3759GDlyJFec6969e1zrurA4V4sWLTB9+nREREQgPDwcQ4YMwZQpUzBv3rxi5/bz88P06dN1FucyMzPD7Nmzcfr0aa6kQUkKi3NNnDgRe/fuxZYtW2BnZ4exY8fiww8/1FloMDk5GeHh4cjOzsagQYPw77//YsaMGfj000+RmpqK4cOHo0+fPvjyyy+xc+dOtGzZEt27dy81DlPSq4VuYWFRrKaEoSsWRUZGIjU1Fd7e3txSdmfPnsXatWthZmZW7C/w/PnzkZWVxT0SEhIMum5FuU+1z8lrcmRKZBdoP+Sq0v+/yFWs2DHZBcpifxgAKs71+jGvx6lvcS5As06ySCRC/fr1oVRqXvNffvkF/v7+GDFiBPdpJDk5GW5ubuDz+VqFvCqbXi10Jycn/PPPP+DxeFAoFFiyZAn3JtFX7969ER0drbVtwoQJaN26NebOnVvsD4dIJNJZxKcqyMyT41lWAQDAQSKGxFJYyRGRqsBaVPy/l0yhKjWpCwW8Elvor6PiXK8YozgXANy+fRtyuRw5OTncesnr1q3DjRs3kJ6ezrXG7e3t8fDhQ7i6uiIqKgpDhw4t9jNUBr0S+tq1azF+/HhER0fDysoKPXv2xK5duwy6sI2NDdq1a6e1zcrKCvXq1Su2vaq7T6NbiA6vd5EAmj70H08/gFpHTufzgGmBLWFnVbYGARXnesUYxbkAoGnTpnjvvfcQFxeHFStWAAC6d++O7t27o2vXrtwnj2+//RajR49Gw4YNq8wNZUDP4lyF8vLywBiDlZUVrl27xn38Kq/AwEB4eXlhzZo1b9y3KhXn2nExDvHpmnK50wNd0dCWyuXWVmUprHT9SQYO3UjSSup8HjDYqwk8HatOciCVwyTFuSIiIvD48WMEBgaiXr16uH37Nr744gtcuHABaWlpegetS1UZy6mPPLkSj59rknldKyEa2FTNbiFSdXg1s4NTPStEPclAZp4cdSyF8G5mV+aWOSElKdNN0eXLlyMoKAgrV66Er68v1q1bh06dOsHV1ZW74VJbPUjO5kYtUO1zUlZ2VkL0drfHUB9H9Ha3p2ROjKJMLfTQ0FDcuXMHjRs3xr1799CuXTucOHECvXv3ruj4qryixbjcqf+cEFKJypTQxWIxN961devWaNWqFSVzAAqlGrFpmrv5ViIzNLUrfrOG1E75+fmVHQKphhhjyM7WDLIw5NN+mRJ6QUEBNySp8KJFn1f3olqGiknLgVJVuNScDXW3EAiFQojFYiQnJ1d2KKQas7W1hVCofzdcmRJ6fn5+sYWgC5/zeDw8evRI7wvXBPdpdih5DZ/Ph5OTk1ZxKUL0UTjR0qBjy7JTfHy8QSevydRqhvspmo9GQjM+XOrTUnNEg8/nm3yNXUIAPaf+k1ceP89FgUJTnqBlQxuYCeilJIRULspCBtJaas6BarcQQiofJXQDMMa4xSz4PB5aNqSETgipfJTQDfAsqwDSfM2i2M0bWOkspkQIIaZW7oQeFRVljDiqlXs0uoUQUgWVO6EvWLDAGHFUK0X7z92o9jkhpIood0I/cuSIMeKoNp7nyJCWLQMANLWzgLXYvJIjIoQQDepD15P26BbqbiGEVB16TUdycXHROb29Ns0Uvf+syGIW1H9OCKlC9Erohw8f5r4uKCjAL7/8gnr16hl04aVLl2L//v24d+8eLCws4Ofnh+XLl8PNzc2g85lCToECCRl5AIAGNiLUs6ba54SQqsOgFYuK8vPze+PyVrr069cPo0aNQqdOnaBUKvH555/j1q1buHPnDqys3jyNvjJWLIqMf4HDNzWL0/Zo2QC93EtekosQQkzNsAowLz1//tzgqnLHjx/Xeh4aGoqGDRsiMjIS/v7+5QmrwlD/OSGkKtMroXfo0IHrQ1epVHj8+DE+++wzowSSlZUFQLPwrS4ymQwymYx7LpVKde5XUWQKFR6laZaasxWbwUFCxZcIIVWLXgm96OLNZmZmaN68ORwcHModhFqtRkhICLp164Z27drp3Gfp0qVYtGhRua9lqIepOVC/7J1yc6Cl5gghVU+5+9CNYfr06Th27BjOnz+Ppk2b6txHVwvd0dHRZH3ov0Uk4PZTzaeIcb7OcGlgXeHXJIQQfejVQr9z5w4WLVqEhw8fQqlUcttv3rxpcAAzZ87E4cOHce7cuRKTOQCIRCKIRJUzqkSpUuNhqma4othcgGb1qPY5IaTq0Suhjxo1CuPGjcOMGTMgEJSvIBVjDLNmzcKBAwcQHh4OFxeXcp2vIsWl50KuVAMA3OxtIOBTdwshpOrRK6ELBAJ88sknRrnwjBkzsHv3bvzxxx+wsbHhRstIJBJYWFStxZa1arfQ6BZCSBWl19T/nj174ty5c0a58MaNG5GVlYXAwEA4ODhwj7179xrl/MaiZgz3X9Y+NxPw4Ep954SQKkqvFvqwYcPQt29f2NjYQCwWgzFm8CLRVeBebJkkZeQjV6a5X9CigTXMzaj8DSGkatIroU+YMAE//PADOnbsWO4+9OqCap8TQqoLvRK6tbU1Jk6cWFGxVDmapeY0CZ0HoBXVPieEVGF69R8MGDAAhw4dqqhYqpy0bBle5MoBAE71rGApLFelBEIIqVB6Zah169YhKysLFhYWEIlEXB/6ixcvKiq+SkW1Wwgh1YleCf369esVFEbVVLT/nJaaI4RUdXoldCcnp4qKo8rJypPjWVYBAKCRRIw6lsJKjogQQkpHKxaV4F4yrUxECKleKm3FoqqO+s8JIdWNXgm9bdu2Ws99fHzg5+eHBQsWGDWoypYnV+Lxc03tcztLIRra0FJzhJCqr1zTHsuzYlFV9jAlG4UTWVs72FDtc0JItVBlViyqSmh2KCGkOqoSKxZVFdnSAihUasSk5QAArIQCNK1rWWmxAICNbeUvdUex6Eax6Eax6GaKWMqU0KVSKV68eIGAgACt7fHx8ZBKpSZZMcgUkhKzkJQjg1Kl6W9p1cgW/ErqbklKzAIPgFubyn8jUiwUC8VSPWIpUx/6Z599hsjIyGLbo6KiMHfuXKMHVRmUSjVSk7MRk57LbXOvpNEthbGkJOdA+XJhjcpCsVAsFEv1iaVMCf3KlSsYOnRose1Dhgwpd3309evXw9nZGWKxGF26dMGVK1fKdT5DRccm4wmTI0WpAgCY8QGX+pWz1FxcQhqsbNSwtVPhZswjvMjNqZQ4KBaKhWKpXrGUKaEXXT+02An4hg+U2bt3L+bMmYOFCxciKioKnp6e6Nu3L1JTUw0+pyGORj/CofsvEJurRmGVdqUa+OtOvEnjAIA7zxKhlmfCRgJYWgHWfDVSE5Nw51kixUKxUCwUS6l4rAwrTbi7u+Py5cvF+sqzsrLQpUsX3Lt3z6CLd+nSBZ06dcKPP/4IAFCr1XB0dMSsWbMwb968Uo+VSqWQSCTIysrSuw//2VMpHtxNhVrNIOercTlXAV0vAg9AFytziCFAK/eGcGhs/C6YorEIzBjsGwO6uu0ZA1KeAkzNp1goFoqFYtGpTAl90aJFiIqKQmhoKOzs7AAAGRkZ+OCDD+Dh4YGvv/5a7wvL5XJYWlrit99+Q3BwMLd9/PjxyMzMxB9//KG1v0wmg0wm455LpVI4OjoalNABIDdHhls3kxGTn4uY3JL7tNzr8tGurikW8+CBzwdK+8CjVgNqtSlWeqJYKBaKxRSxZOcArVs5wcraOJMXyzTK5csvv8TEiRPh6OiIli1bAgAePnyIoUOHGjxLND09HSqVCvb29lrb7e3tdbb4ly5dikWLFhl0LV2srEXo2MUR0eGlf7rIUwJmZlVjYpHmzUGxvI5i0Y1i0a0qxQJbGC2ZA2VM6AKBADt27MBXX32FqKgoAIC3tzdatGhhtEDeZP78+ZgzZw73vLCFXh4CAR8WlnyglBa6pRmgVJpm/dM3vdHUaga1iW7WUywUC8VS8bHwzY376V+viUUtWrQwWhKvX78+BAIBUlJStLanpKSgUaNGxfYXiUQQiYxfU8WjYR3EpqWX2IfeqbUDXOrbGf26usQnpkOW+0Jnf5uaMTR0bIK6VtYUC8VCsdSQWJzq2xf/RjlU2hL2QqEQPj4+OHXqFLdNrVbj1KlT8PX1NVkc1jBHO2sBXn+9eQC8GgpNlswBgMl4yHwOvH5XgzEgXyU02ZuQYqFYKJbqGUulLpI5Z84cjB8/Hh07dkTnzp2xZs0a5ObmYsKECSaLIVsqQ1OxJdq0skRU4nPkytSwNOehsdoc9USmnfafLZWBBxFs6tkiJfcF1EoVeOBDkcqHhdi0FR8pFoqFYqmGsbBKtm7dOtasWTMmFApZ586d2aVLl8p0XFZWFgPAsrKyynX9mAdpTKlUFduuVKpYzIO0cp2bYqFYKBaKxZSxlGnYYlVUnnHohBBSE1VaHzohhBDjqrYtdMYYsrOzYWNDC1AQQghQjRM6IYQQbdTlQgghNQQldEIIqSEooRNCSA1RqROLKkrhDVNCCKkpyjIApEYm9OzsbEgkksoOgxBCjKYsc25q5CgXQ1vohRUcExISKn2yEsVCsVAsFEtRtbaFzuPxyvXLs7W1rfRffiGKRTeKRTeKRbfaEgvdFCWEkBqCEjohhNQQlNCLEIlEWLhwYYUspEGxUCwUC8VS0bHUyJuihBBSG1ELnRBCaghK6IQQUkNQQieEkBqCEjohhNQQtS6hr1+/Hs7OzhCLxejSpQuuXLlS6v779u1D69atIRaL0b59exw9erRSYvnpp5/Qo0cP2NnZwc7ODkFBQW+MvaJiCQ0NBY/H03qIxeJKiQUA1qxZAzc3N1hYWMDR0RH//e9/UVBQUO44zp07h0GDBqFx48bg8Xg4ePDgG48JDw+Ht7c3RCIRXF1dERoaWu44DIll//796NOnDxo0aABbW1v4+vrixIkTlRJLeHh4sfcLj8dDcnKyyWMBgF27dsHT0xOWlpZwcHDAxIkT8fz583LFsXTpUnTq1Ak2NjZo2LAhgoODcf/+/TceZ+z8UqsS+t69ezFnzhwsXLgQUVFR8PT0RN++fZGamqpz/4sXL+K9997DBx98gGvXriE4OBjBwcG4deuWyWMJDw/He++9hzNnzuDff/+Fo6Mj3nrrLSQlJZk8FkAz2+3Zs2fc4/Hjx+WOw5BYdu/ejXnz5mHhwoW4e/cu/ve//2Hv3r34/PPPyx1Lbm4uPD09sX79+jLtHxcXhwEDBqBnz564fv06QkJCMGnSJKMkUn1jOXfuHPr06YOjR48iMjISPXv2xKBBg3Dt2jWTx1Lo/v37Wu+Zhg0bmjyWCxcuYNy4cfjggw9w+/Zt7Nu3D1euXMHkyZPLFcfZs2cxY8YMXLp0CSdPnoRCocBbb72F3NzcEo+pkPxi9GWnq7DOnTuzGTNmcM9VKhVr3LgxW7p0qc79R4wYwQYMGKC1rUuXLmzq1Kkmj+V1SqWS2djYsB07dpg8lu3btzOJRFLu6xojlhkzZrBevXppbZszZw7r1q2bUeMCwA4cOFDqPp999hlr27at1raRI0eyvn37mjwWXdq0acMWLVpk8ljOnDnDALCMjAyjXtuQWFauXMmaN2+utW3t2rWsSZMmRo0lNTWVAWBnz54tcZ+KyC+1poUul8sRGRmJoKAgbhufz0dQUBD+/fdfncf8+++/WvsDQN++fUvcvyJjeV1eXh4UCgXq1q1bKbHk5OTAyckJjo6OeOedd3D79u1yxWFoLH5+foiMjOS6ZR49eoSjR4+if//+5Y5HXxX1fjEGtVqN7Ozscr9fysPLywsODg7o06cPLly4UCkx+Pr6IiEhAUePHgVjDCkpKfjtt9+M/n7JysoCgFJf74p4v9SahJ6eng6VSgV7e3ut7fb29iX25SUnJ+u1f0XG8rq5c+eicePGxd4QpojFzc0N27Ztwx9//IGdO3dCrVbDz88PiYmJJo9l9OjR+Oabb9C9e3eYm5ujRYsWCAwMNEqXi75Ker9IpVLk5+ebPJ6iVq1ahZycHIwYMcLk13ZwcMCmTZvw+++/4/fff4ejoyMCAwMRFRVl8li6deuGXbt2YeTIkRAKhWjUqBEkEone3UelUavVCAkJQbdu3dCuXbsS96uI/FJrEnpNsmzZMoSFheHAgQNGvRlZVr6+vhg3bhy8vLwQEBCA/fv3o0GDBti8ebPJYwkPD8eSJUuwYcMGREVFYf/+/Thy5Ai+/fZbk8dSVe3evRuLFi3Cr7/+apR+a325ublh6tSp8PHxgZ+fH7Zt2wY/Pz+sXr3a5LHcuXMHs2fPxldffYXIyEgcP34c8fHxmDZtmtGuMWPGDNy6dQthYWFGO2dZ1cjyubrUr18fAoEAKSkpWttTUlLQqFEjncc0atRIr/0rMpZCq1atwrJly/D333/Dw8OjXHGUN5ZC5ubm6NChA2JiYkwey4IFC/D+++9j0qRJAID27dsjNzcXU6ZMwRdffAE+33RtlpLeL7a2trCwsDBZHEWFhYVh0qRJ2LdvX7k/zRlT586dcf78eZNfd+nSpejWrRs+/fRTAICHhwesrKzQo0cPLF68GA4ODuU6/8yZM3H48GGcO3cOTZs2LXXfisgvtaaFLhQK4ePjg1OnTnHb1Go1Tp06BV9fX53H+Pr6au0PACdPnixx/4qMBQBWrFiBb7/9FsePH0fHjh3LFUN5YylKpVIhOjq63P8ZDIklLy+vWNIWCAQANAudmFJFvV8MtWfPHkyYMAF79uzBgAEDKiWGkly/fr3c7xdDVNT7hTGGmTNn4sCBAzh9+jRcXFzeeEyFvF8Mvp1aDYWFhTGRSMRCQ0PZnTt32JQpU1idOnVYcnIyY4yx999/n82bN4/b/8KFC8zMzIytWrWK3b17ly1cuJCZm5uz6Ohok8eybNkyJhQK2W+//caePXvGPbKzs00ey6JFi9iJEydYbGwsi4yMZKNGjWJisZjdvn3b5LEsXLiQ2djYsD179rBHjx6xv/76i7Vo0YKNGDGi3LFkZ2eza9eusWvXrjEA7Pvvv2fXrl1jjx8/ZowxNm/ePPb+++9z+z969IhZWlqyTz/9lN29e5etX7+eCQQCdvz4cZPHsmvXLmZmZsbWr1+v9X7JzMw0eSyrV69mBw8eZA8fPmTR0dFs9uzZjM/ns7///tvksWzfvp2ZmZmxDRs2sNjYWHb+/HnWsWNH1rlz53LFMX36dCaRSFh4eLjW652Xl8ftY4r8UqsSOmOMrVu3jjVr1owJhULWuXNndunSJe57AQEBbPz48Vr7//rrr6xVq1ZMKBSytm3bsiNHjlRKLE5OTgxAscfChQtNHktISAi3r729Pevfvz+LiooyShz6xqJQKNjXX3/NWrRowcRiMXN0dGQffvihUYbIFQ63e/1ReP3x48ezgICAYsd4eXkxoVDImjdvzrZv317uOAyJJSAgoNT9TRnL8uXLud9P3bp1WWBgIDt9+nS54zAkFsY0wxTbtGnDLCwsmIODAxszZgxLTEwsVxy6YgCg9fs3RX6h8rmEEFJD1Jo+dEIIqekooRNCSA1BCZ0YxNnZGW5ubvDy8uIe0dHRBp8vIiICI0eONGKEpvP111+XWgxs06ZN8PDwgJeXF1q3bo0xY8aU+diK9NFHH8HZ2Rk8Hg/Xr1/X+/iFCxcafCypIOXqgSe1lpOTE7t27ZpJrqVQKExyHUOhlDolV69eZS4uLuz58+eMMcbUajWLjIws07EV7ezZsywhIcGg3+Xly5fZ22+/bdL3AXkzaqETo+PxeFiyZAk6d+4MFxcXbN++HYCmbOnAgQO5/RhjaN68OW7cuIHw8HB4eXkBAOLj41GnTh3MnTsX3t7e+PHHHxETE4OgoCCupVu0TGpJ1wM0nyS+/PJL+Pn5wdHREZs2bcL27dvh6+sLZ2dnrdl8V69eRa9evdCxY0d06NAB+/bt04pn4cKF8PHxgaurK1fmtHCGYY8ePeDl5VWsKmRiYiJsbGxgY2PDxert7V3isdnZ2Zg8eTI6d+4MDw8PTJkyBXK5HAAQGBiIWbNmoVOnTnB1dcXHH3/MjZ1evHgx3N3duU9LZal+6e/vX+Lkl5JeC0AzlnvmzJmVMjOYvEFl/0Uh1ZOTkxNr1aoV8/T05B6FY24BsFWrVjHGGLt79y6ztrZmCoWC5eXlsXr16rFnz54xxhg7ffo08/b2Zoxphp95enoyxhiLi4tjALQqSXbu3Jlt2rSJMcbYgwcPWN26dVl8fHyp1yuMMyQkhDHG2MOHD5lYLGbffvstY4yxK1eusPr16zPGGMvIyGBeXl7s6dOnjDHG0tLSmKOjI0tMTOTi+e233xhjjB07doy1atWKiw2ltLJzc3NZt27dWKNGjdiIESPYunXr2IsXL0o8dvLkydzPrVar2QcffMBWrFjBGNMMe+vVqxeTy+UsNzeX+fj4sF27drEXL14wiUTCvf65ubksPz+/1N9fUa+3skt7LRjTVLjctm2bzmNJ5aKETgxS2n9kAFzSZoyxOnXqsISEBMYYY1OmTOES1Lhx49i6desYY8UTurm5OVOpVIwxxqRSKTMzM9Pqehk8eDD75Zdf3ng9Jycn9u+//2p97+7du4wxTcLk8/ksIyODHTlyhNna2mr9gXJ0dGSnTp1icXFxTCwWM7VazRhjLDMzkwkEAq2ft7RuE7VazaKiotgPP/zAevbsyZo2bcp1wbx+bIMGDVi7du24GFq1asWmTJnCGNMk9NDQUG7f1atXswkTJjClUsk6duzIhgwZwjZt2sT97GX1+u+ytNfir7/+YgMHDizxWFK5ak0tF2JaRYuGCQQCKJVKAMDEiRMxYcIETJ8+HYcPHy6xQJOlpWWpdVh4PF6Zrqfre4XPC1fOUSqVYIyhbdu2uHjxYrFrxcfHQyQScdcUCARQqVQlxqYr1g4dOqBDhw6YNWsW2rRpg/DwcAwZMqTYvowx/P7772jVqlWZzy0QCHDp0iVcvHgR4eHh6Nq1K/bs2YMePXqUOcbXYyjptZg/fz6ioqLg7OwMQNOl1L9/f2zevBmDBg0y6HrEeKgPnZhUly5dAACffPIJgoKCylSf28bGBt7e3lzfeExMDM6fPw9/f3+jxeXn54e4uDj8/fff3Lbr169z/ddviq+w/vXr7t27h5s3b3LPExISkJaWhubNm+s8Njg4GMuXL+f+IGVkZGgVPdu5cycUCgXy8/Oxe/duBAUFITs7GykpKejRowcWLFiA7t27cysTjRs3DgcOHNDjlSj9tVi6dCmSkpIQHx+P+Ph4NG3aFEePHqVkXkVQQicGGzlypNawxTNnzpTpuAkTJmDz5s2YMGFCma+1a9cu7N27F56enhg2bBi2bt2KZs2aGRp6MXZ2djhy5AiWLFkCT09PtGnTBvPmzYNarX7jsR9//DH69Omj86ZoXl4eZs2axQ3xHDRoEJYtW8bdAH792NWrV8PCwgJeXl7w8PBA7969ER8fz53P3d0d3bp1Q/v27dGjRw+MGjUKWVlZGDJkCNq3bw8PDw8oFAqMHz8egGY4qKOjo864p06diqZNmyIxMRF9+/aFq6truV8LUrlo6j8h1URgYCBCQkIQHBxcpv3T0tIwevRonDx5smIDI1UGtdAJqaEaNGhAybyWoRY6IYTUENRCJ4SQGoISOiGE1BCU0AkhpIaghE4IITUEJXRCCKkhKKETQkgNQQmdEEJqCErohBBSQ1BCJ4SQGuL/AaYA9g/Y+mxsAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw experiment figures\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from causal_rl.algo.reward_shaping.constants import MAX_EPISODES\n",
    "\n",
    "env_name = 'causal_gym/RobotWalk-v0'\n",
    "palette = sns.color_palette('Set3')\n",
    "\n",
    "METHOD_NAMES = ['No Shaping', 'Causal Upper Bound (Ours)', 'Confounded Values good', 'Confounded Values bad']\n",
    "COLORS = [palette[0], palette[2], palette[8], palette[4], palette[5]]\n",
    "\n",
    "\n",
    "print(env_name)\n",
    "sns.reset_defaults()\n",
    "stepsize = MAX_EPISODES[env_name]//8\n",
    "max_y = 0\n",
    "for i, method in enumerate(METHOD_NAMES):\n",
    "    full_regret = []\n",
    "    full_seeds = []\n",
    "    full_steps = []\n",
    "    for seed in [5678,]:\n",
    "        with open(f'regrets/REG-robotwalk-{method}.json', 'r') as f:\n",
    "            regret = json.load(f)\n",
    "            regret = (np.array(regret) + 1).tolist() #for better visuals in log scale\n",
    "            max_y = max(max(np.log(regret)), max_y)\n",
    "            full_regret += regret[::stepsize-1]\n",
    "            full_seeds += [seed,]*len(regret[::stepsize-1])\n",
    "            full_steps += list(range(len(regret)))[::stepsize-1]\n",
    "    regret = pd.DataFrame(data={'step':full_steps, 'reg':np.log(full_regret), 'seed':full_seeds}).sort_values('step', ascending=True)\n",
    "    # shift the x-axis a little bit to get the last element\n",
    "    marker = 'o' if method != 'Causal Upper Bound (Ours)' else '*'\n",
    "    markersize = 6 if method != 'Causal Upper Bound (Ours)' else 10\n",
    "    alpha = 1.0 if method != 'Causal Upper Bound (Ours)' else 1.0\n",
    "    ax = sns.lineplot(data=regret, x='step', y='reg', label=f'{method}', legend='brief', linewidth=2, color=COLORS[i], marker=marker, markersize=markersize, mew=0, alpha=alpha)   \n",
    "\n",
    "\n",
    "ax.set_xlabel('Environment Steps, 1e'+str(len(str(MAX_EPISODES[env_name])[1:])), fontsize=8, labelpad=0)\n",
    "ax.set_ylabel('Cumu. Regrets, log-scale', fontsize=8, labelpad=0)\n",
    "\n",
    "magnitude = 10**int(f'{MAX_EPISODES[env_name]:.1E}'.split('+')[1])\n",
    "ax.set_xticks(range(0, MAX_EPISODES[env_name]+1, stepsize), labels=[f'{i/magnitude:.1f}' for i in range(0, MAX_EPISODES[env_name]+1, stepsize)], fontsize=12)\n",
    "ax.set_yticks(range(0, int(np.ceil(max_y))+1, 2), labels=[str(i) for i in np.arange(0, int(np.ceil(max_y))+1, 2)], fontsize=12)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='10') \n",
    "# Calculate maximum label length\n",
    "max_label_length = max(len(label.get_text()) for label in plt.legend().get_texts())\n",
    "# Adjust font size based on label length\n",
    "fontsize = 11 - max_label_length * 0.2\n",
    "plt.legend(fontsize=fontsize)\n",
    "\n",
    "sns.despine(offset=5)\n",
    "sns.set_theme(font_scale=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764bb451",
   "metadata": {},
   "source": [
    "Since this is a an easy example, both no shaping and shaping with the optimal behavioral policy values method can converge \n",
    "easily to the optimal policy. Note that the optimal behavioral value is also a valid upper bound of optimal interventional policy value.\n",
    "\n",
    "Only shaping with the value of the bad behavioral policy cannot converge efficiently. Yet after using our causal bound with data from both the good and the bad policy, the agent can still converge well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
